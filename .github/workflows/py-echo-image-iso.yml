name: "üêç PyPkg + Echo/CopyPlan + Docker Image + ISO + Push + Release + Deploy (no-skip + cache, v2)"

on:
  workflow_dispatch:
    inputs:
      package_name: { description: "Ìå®ÌÇ§ÏßÄ Ïù¥Î¶Ñ", required: true, default: "mypkg" }
      package_version: { description: "Î≤ÑÏ†Ñ", required: true, default: "0.1.0" }
      dirs_count: { description: "echo_mass ÎîîÎ†âÌÜ†Î¶¨ Í∞úÏàò", required: true, default: "500" }
      iso_label: { description: "ISO ÎùºÎ≤®", required: true, default: "ECHO_ISO" }
      inject_info_json: { description: "ISO Ï£ºÏûÖ JSON", required: false, default: "{\"env\":\"dev\",\"team\":\"finops\"}" }
      metadata_json: { description: "Î©îÌÉÄ JSON", required: false, default: "{\"author_name\":\"Your Name\",\"author_email\":\"you@example.com\",\"license_name\":\"MIT\"}" }
      image_ref: { description: "Ïù¥ÎØ∏ÏßÄ (name:tag)", required: true, default: "mypkg-app:latest" }
      build_docker: { description: "Docker ÎπåÎìú/Ï†ÄÏû•", required: true, type: boolean, default: true }
      copy_plan_json:
        description: "Î≥µÏÇ¨ Í≥ÑÌöç(JSON)"
        required: false
        default: "{\"plans\":[{\"src\":\"samples\",\"dest_rel\":\"extra/samples\",\"include_globs\":[\"**/*\"],\"exclude_globs\":[\"**/.git/**\",\"**/.github/**\"],\"max_mb\":100,\"include_in_iso\":true,\"required\":false}]}"
      advanced_json:
        description: "ÌôïÏû• ÏÑ§Ï†ï(JSON)"
        required: false
        default: "{\"packaging\":{\"mode\":\"pip\"},\"ghcr\":{\"enable\":true},\"dockerhub\":{\"enable\":true},\"release\":{\"enable\":true},\"server\":{\"enable\":true}}"

permissions:
  contents: write
  packages: write
  actions: read

concurrency:
  group: pypkg-echo-${{ github.ref }}
  cancel-in-progress: true

env:
  TZ: Asia/Seoul
  LOG_DIR: .github/echo_logs
  ECHO_OK: "‚úÖ"
  ECHO_WARN: "‚ö†Ô∏è"
  ECHO_FAIL: "‚ùå"
  DOCKER_BUILDKIT: "1"

jobs:
  all-in-one:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Global echo helpers
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p "$GITHUB_WORKSPACE" "$LOG_DIR"
          cat > "$GITHUB_WORKSPACE/.bashenv" <<'SH'
          ECHO_OK="${ECHO_OK:-‚úÖ}"; ECHO_WARN="${ECHO_WARN:-‚ö†Ô∏è}"; ECHO_FAIL="${ECHO_FAIL:-‚ùå}"
          LOG_DIR="${LOG_DIR:-.github/echo_logs}"; mkdir -p "$LOG_DIR"
          SAFE_LOG="${SAFE_LOG:-${LOG_DIR}/run-$(date +%Y%m%d%H%M%S).log}"
          echoe(){ printf '%s %s\n' "${ECHO_OK}" "$*"; }
          warn(){  printf '%s %s\n' "${ECHO_WARN}" "$*"; }
          fail(){  printf '%s %s\n' "${ECHO_FAIL}" "$*"; }
          logf(){  printf '%s\n' "$*" | tee -a "$SAFE_LOG"; }
          SH
          echo "BASH_ENV=$GITHUB_WORKSPACE/.bashenv" >> "$GITHUB_ENV"
          source "$GITHUB_WORKSPACE/.bashenv"
          echoe "helpers loaded"; logf "helpers ready"

      - name: Fail trap
        shell: bash
        run: |
          set -Eeuo pipefail
          trap 'echo "‚ùå Failed at line $LINENO"; tail -n 200 ${LOG_DIR}/run-* 2>/dev/null || true' ERR
          echo "‚úÖ trap ready"

      - name: Install toolchain
        shell: bash
        run: |
          set -Eeuo pipefail
          logf "Installing tools"
          sudo apt-get update -y
          sudo apt-get install -y python3 python3-venv python3-pip python3-setuptools python3-wheel \
            git jq rsync xorriso genisoimage dosfstools openssh-client zstd

      - name: Parse inputs
        id: parse
        shell: bash
        run: |
          set -Eeuo pipefail
          source "$GITHUB_WORKSPACE/.bashenv"
          MJ='${{ inputs.metadata_json }}'
          A_NAME=$(printf '%s' "$MJ" | jq -r '.author_name // "Your Name"')
          A_EMAIL=$(printf '%s' "$MJ" | jq -r '.author_email // "you@example.com"')
          L_NAME=$(printf '%s' "$MJ" | jq -r '.license_name // "MIT"')
          IMG='${{ inputs.image_ref }}'
          if [[ "$IMG" == *:* ]]; then IMG_NAME="${IMG%%:*}"; IMG_TAG="${IMG##*:}"; else IMG_NAME="$IMG"; IMG_TAG="latest"; fi
          CP='${{ inputs.copy_plan_json }}'
          printf '%s' "$CP"  | jq . >/dev/null
          ADV_RAW='${{ inputs.advanced_json }}'
          printf '%s' "$ADV_RAW" | jq . >/dev/null
          OWNER="${GITHUB_REPOSITORY_OWNER:-$(echo "${GITHUB_REPOSITORY:-unknown/unknown}"|cut -d/ -f1)}"
          DEF_GHCR="ghcr.io/${OWNER}/${{ inputs.package_name }}"
          DEF_DH="${OWNER,,}/${{ inputs.package_name }}"
          ADV=$(printf '%s' "$ADV_RAW" | jq \
            --arg ghcr "$DEF_GHCR" --arg dh "$DEF_DH" '
              .ghcr |= ( . // {} | .repo=(.repo // $ghcr) | .tag=(.tag // "latest") | .enable=(.enable // true)) |
              .dockerhub |= ( . // {} | .repo=(.repo // $dh) | .tag=(.tag // "latest") | .enable=(.enable // true)) |
              .release |= ( . // {} | .enable=(.enable // true) | .tag=(.tag // "") | .draft=(.draft // false) | .prerelease=(.prerelease // false)) |
              .server  |= ( . // {} | .enable=(.enable // true) | .host=(.host // "") | .user=(.user // "ubuntu") | .port=(.port // 22) |
                            .deploy_path=(.deploy_path // ("/opt/"+"${{ inputs.package_name }}")) |
                            .service_name=(.service_name // "${{ inputs.package_name }}") |
                            .start_cmd=(.start_cmd // ("python -m "+"${{ inputs.package_name }}")) |
                            .use_sudo=(.use_sudo // true) )')
          {
            echo "author_name=$A_NAME"; echo "author_email=$A_EMAIL"; echo "license_name=$L_NAME"
            echo "image_name=$IMG_NAME"; echo "image_tag=$IMG_TAG"
            echo "pkg_mode=$(printf '%s' "$ADV" | jq -r '.packaging.mode // "pip"')"
            echo "ghcr_enable=$(printf '%s' "$ADV" | jq -r '.ghcr.enable')"
            echo "ghcr_repo=$(printf '%s' "$ADV" | jq -r '.ghcr.repo')"
            echo "ghcr_tag=$(printf '%s' "$ADV" | jq -r '.ghcr.tag')"
            echo "dh_enable=$(printf '%s' "$ADV" | jq -r '.dockerhub.enable')"
            echo "dh_repo=$(printf '%s' "$ADV" | jq -r '.dockerhub.repo')"
            echo "dh_tag=$(printf '%s' "$ADV" | jq -r '.dockerhub.tag')"
            echo "rel_enable=$(printf '%s' "$ADV" | jq -r '.release.enable')"
            echo "rel_tag=$(printf '%s' "$ADV" | jq -r '.release.tag // ""')"
            echo "rel_draft=$(printf '%s' "$ADV" | jq -r '.release.draft')"
            echo "rel_prerelease=$(printf '%s' "$ADV" | jq -r '.release.prerelease')"
            echo "dep_enable=$(printf '%s' "$ADV" | jq -r '.server.enable')"
            echo "dep_host=$(printf '%s' "$ADV" | jq -r '.server.host')"
            echo "dep_user=$(printf '%s' "$ADV" | jq -r '.server.user')"
            echo "dep_port=$(printf '%s' "$ADV" | jq -r '.server.port')"
            echo "dep_path=$(printf '%s' "$ADV" | jq -r '.server.deploy_path')"
            echo "dep_svc=$(printf '%s' "$ADV" | jq -r '.server.service_name')"
            echo "dep_cmd=$(printf '%s' "$ADV" | jq -r '.server.start_cmd')"
            echo "dep_sudo=$(printf '%s' "$ADV" | jq -r '.server.use_sudo')"
          } | tee -a "$LOG_DIR/parsed_inputs.env" >> "$GITHUB_OUTPUT"
          printf '%s' "$CP"   > copy_plan.json
          printf '%s' "$ADV"  > advanced.json
          logf "copy_plan.json & advanced.json saved"

      - name: Validate inputs
        shell: bash
        run: |
          set -Eeuo pipefail
          [[ "${{ inputs.package_name }}" =~ ^[a-z0-9_]+$ ]] || { echo "‚ùå invalid package_name"; exit 1; }
          [[ "${{ inputs.package_version }}" =~ ^[0-9]+\.[0-9]+\.[0-9]+(-[0-9A-Za-z\.-]+)?$ ]] || { echo "‚ùå invalid version"; exit 1; }
          [[ "${{ inputs.image_ref }}" =~ ^[a-z0-9._/-]+(:[a-zA-Z0-9._-]+)?$ ]] || { echo "‚ùå invalid image_ref"; exit 1; }
          echo "‚úÖ input validation passed"

      - name: Setup Python
        uses: actions/setup-python@v5
        with: { python-version: "3.11" }

      - name: Create package skeleton + echo_mass (always)
        shell: bash
        run: |
          set -Eeuo pipefail
          source "$GITHUB_WORKSPACE/.bashenv"
          P="${{ inputs.package_name }}"; V="${{ inputs.package_version }}"
          A="${{ steps.parse.outputs.author_name }}"; E="${{ steps.parse.outputs.author_email }}"; L="${{ steps.parse.outputs.license_name }}"
          ROOT="workspace/${P}"; PKG_DIR="$ROOT/src/${P}"; TEST_DIR="$ROOT/tests"; DOC_DIR="$ROOT/docs"
          mkdir -p "$PKG_DIR" "$TEST_DIR" "$DOC_DIR"
          cat > "$ROOT/pyproject.toml" <<'PYT'
          [build-system]
          requires = ["setuptools>=68", "wheel"]
          build-backend = "setuptools.build_meta"
          [project]
          name = "__PKG_NAME__"
          version = "__PKG_VER__"
          description = "Auto-generated package with EchoOps"
          authors = [{ name="__AUTHOR__", email="__EMAIL__"}]
          license = { text="__LICENSE__" }
          readme = "README.md"
          requires-python = ">=3.9"
          classifiers = ["Programming Language :: Python :: 3","License :: OSI Approved :: MIT License"]
          [tool.setuptools.packages.find]
          where = ["src"]
          PYT
          sed -i "s/__PKG_NAME__/${P}/g;s/__PKG_VER__/${V}/g;s/__AUTHOR__/${A}/g;s/__EMAIL__/${E}/g;s/__LICENSE__/${L}/g" "$ROOT/pyproject.toml"
          echo -e "# Auto Generated Python Package\n- EchoOps generated." > "$ROOT/README.md"
          cat > "$PKG_DIR/__init__.py" <<'PY'
          __all__ = ["hello"]; __version__="__VER__"
          def hello(name: str = "World") -> str: return f"Hello, {name}!"
          PY
          sed -i "s/__VER__/${V}/g" "$PKG_DIR/__init__.py"
          cat > "$TEST_DIR/test_hello.py" <<'PY'
          from __future__ import annotations
          from __pkg__.__init__ import hello
          def test_hello(): assert hello("Echo") == "Hello, Echo!"
          PY
          sed -i "s/__pkg__/${P}/g" "$TEST_DIR/test_hello.py"
          # Dockerfile
          cat > "$ROOT/Dockerfile" <<'DOCKER'
          FROM python:3.11-slim
          WORKDIR /app
          COPY . /app
          RUN pip install --no-cache-dir .
          CMD ["python","-c","import __PKG__; print(__PKG__.hello('Docker'))"]
          DOCKER
          sed -i "s/__PKG__/${P}/g" "$ROOT/Dockerfile"
          # echo_mass + perm_apply.sh ÏÉùÏÑ±
          EM="$ROOT/echo_mass"; mkdir -p "$EM"
          cat > "$EM/perm_apply.sh" <<'SH'
          #!/usr/bin/env bash
          set -Eeuo pipefail
          echo "perm started: $(date)"
          base="$(dirname "$0")"
          for i in $(seq 1 ${DIRS_COUNT:-500}); do d=$(printf "%s/dir_%03d" "$base" "$i"); mkdir -p "$d"; echo "ECHO $(date -Iseconds) $d"; done
          echo "done: $(date)"
          SH
          chmod +x "$EM/perm_apply.sh"
          DIRS_COUNT="${{ inputs.dirs_count }}" bash "$EM/perm_apply.sh" | tee "$EM/perm.log"

      - name: Pip cache (stable key)
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.cache/pip-tools
          key: pip-${{ runner.os }}-${{ hashFiles('workspace/**/pyproject.toml') }}

      - name: Warm pip wheel cache (artifactÎèÑ ÏÉùÏÑ±)
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p .pip-wheelhouse
          python -m pip install --upgrade pip
          pip download --only-binary=:all: --dest .pip-wheelhouse build pytest packaging pluggy iniconfig pygments pyproject_hooks || true
          tar -I 'zstd -T0 -19' -cf pip-wheelhouse.tzst -C .pip-wheelhouse .
          echo "üì¶ wheelhouse packed: pip-wheelhouse.tzst (for reuse)"

      - name: Upload wheel cache artifact
        uses: actions/upload-artifact@v4
        with:
          name: pip-wheelhouse-${{ github.run_id }}
          path: pip-wheelhouse.tzst
          retention-days: 7
          if-no-files-found: warn

      - name: Install test deps (from cache if Í∞ÄÎä•)
        shell: bash
        run: |
          set -Eeuo pipefail
          if [[ -f pip-wheelhouse.tzst ]]; then mkdir -p .pip-wheelhouse-restore && tar -I zstd -xf pip-wheelhouse.tzst -C .pip-wheelhouse-restore || true; fi
          python -m pip install --upgrade pip
          if compgen -G ".pip-wheelhouse-restore/*.whl" > /dev/null; then
            pip install --no-index --find-links .pip-wheelhouse-restore build pytest || pip install build pytest
          else
            pip install build pytest
          fi

      - name: Run tests (pytest)
        shell: bash
        working-directory: workspace/${{ inputs.package_name }}
        env: { PYTHONPATH: src }
        run: |
          set -Eeuo pipefail
          pytest -q

      - name: Build package (pip/poetry/conda)
        shell: bash
        run: |
          set -Eeuo pipefail
          MODE="${{ steps.parse.outputs.pkg_mode }}"
          P="${{ inputs.package_name }}"; ROOT="workspace/${P}"
          case "$MODE" in
            poetry) python3 -m pip install --upgrade pip poetry build; (cd "$ROOT" && poetry build);;
            conda)
              sudo apt-get update -y && sudo apt-get install -y wget bzip2
              MINI="$HOME/miniconda"; wget -qO ~/miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
              bash ~/miniconda.sh -b -p "$MINI"; source "$MINI/etc/profile.d/conda.sh"
              conda create -y -n "${P}" python=3.11; conda activate "${P}"
              pip install --upgrade pip; (cd "$ROOT" && pip install .); pip install conda-pack
              mkdir -p "$ROOT/dist"; conda pack -n "${P}" -o "$ROOT/dist/${P}-env.tar.gz"
              ;;
            *) python3 -m pip install --upgrade pip build; python3 -m build "$ROOT";;
          esac
          ls -al "$ROOT/dist" | tee -a "$LOG_DIR/dist.txt"

      - name: Ensure all copy_plan sources exist (auto-create with placeholder)
        shell: bash
        run: |
          set -Eeuo pipefail
          ROOT="workspace/${{ inputs.package_name }}"
          jq -r '.plans[].src' copy_plan.json | while read -r s; do
            [[ -z "$s" || "$s" == "null" ]] && continue
            for base in "$GITHUB_WORKSPACE" "$ROOT"; do
              [[ -d "$base/$s" ]] || { mkdir -p "$base/$s"; echo "placeholder" > "$base/$s/README.txt"; }
            done
          done
          echo "‚úÖ sources ensured"

      - name: Copy plan dry-run summary
        shell: bash
        run: |
          set -Eeuo pipefail
          jq -r '.plans[] | [.src, .dest_rel, (.include_globs|join("|")), (.exclude_globs|join("|")), (.max_mb|tostring)] | @tsv' copy_plan.json > /tmp/cp.tsv || { echo "‚ö†Ô∏è jq pretty failed"; jq -c '.plans[]' copy_plan.json || true; }
          [[ -f /tmp/cp.tsv ]] && awk -F'\t' '{printf "SRC=%s -> DEST=%s | include:[%s] exclude:[%s] max:%sMB\n",$1,$2,$3,$4,$5}' /tmp/cp.tsv || true

      - name: Copy directories per plan (manifest + checksums)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"; ROOT="workspace/${P}"; PLAN_FILE="copy_plan.json"; DEST_BASE="$ROOT"
          mkdir -p "$ROOT/extra_manifests"
          MANIFEST_CSV="$ROOT/extra_manifests/manifest-$(date +%Y%m%d%H%M%S).csv"
          echo "src,resolved_src,dest_rel,relpath,bytes,sha256" > "$MANIFEST_CSV"
          COUNT_PLANS=$(jq -r '.plans | length' "$PLAN_FILE")
          for i in $(seq 0 $((COUNT_PLANS-1))); do
            SRC=$(jq -r ".plans[$i].src" "$PLAN_FILE")
            DEST_REL=$(jq -r ".plans[$i].dest_rel // \"extra\"" "$PLAN_FILE")
            MAX_MB=$(jq -r ".plans[$i].max_mb // 100" "$PLAN_FILE")
            INCLUDE_ISO=$(jq -r ".plans[$i].include_in_iso // true" "$PLAN_FILE")
            REQUIRED=$(jq -r ".plans[$i].required // false" "$PLAN_FILE")
            mapfile -t INCLUDES < <(jq -r ".plans[$i].include_globs[]?" "$PLAN_FILE")
            mapfile -t EXCLUDES < <(jq -r ".plans[$i].exclude_globs[]?" "$PLAN_FILE")
            RESOLVED_SRC=""
            for base in "$GITHUB_WORKSPACE" "$DEST_BASE" ""; do [[ -d "$base/$SRC" ]] && { RESOLVED_SRC="$base/$SRC"; break; }; done
            if [[ -z "$RESOLVED_SRC" ]]; then
              [[ "$REQUIRED" == "true" ]] && { echo "‚ùå required src not found: $SRC"; exit 1; } || { echo "‚ö†Ô∏è src not found: $SRC"; continue; }
            fi
            DEST_DIR="$DEST_BASE/$DEST_REL"; mkdir -p "$DEST_DIR"
            RSYNC_ARGS=(-a --delete --prune-empty-dirs)
            for p in "${INCLUDES[@]}";  do RSYNC_ARGS+=(--include "$p"); done
            for p in "${EXCLUDES[@]}";  do RSYNC_ARGS+=(--exclude "$p"); done
            RSYNC_ARGS+=(--exclude '.git/' --exclude '.github/' --include '*/' --exclude '*')
            TMP_STAGE="$(mktemp -d)"; rsync "${RSYNC_ARGS[@]}" "$RESOLVED_SRC/" "$TMP_STAGE/"
            TOTAL_BYTES=$(du -sb "$TMP_STAGE" | awk '{print $1}'); LIMIT_BYTES=$((MAX_MB * 1024 * 1024))
            if (( TOTAL_BYTES > LIMIT_BYTES )); then
              mkdir -p "$DEST_DIR"; REMAIN=$LIMIT_BYTES
              mapfile -t FILES < <(find "$TMP_STAGE" -type f -printf '%T@ %p\n' | sort -nr | awk '{sub($1 FS,""); print}')
              for f in "${FILES[@]}"; do sz=$(stat -c%s "$f"); (( sz <= REMAIN )) || continue
                rel="${f#"$TMP_STAGE/"}"; mkdir -p "$DEST_DIR/$(dirname "$rel")"; cp -a "$f" "$DEST_DIR/$rel"; REMAIN=$((REMAIN - sz)); done
            else
              rsync -a --delete "$TMP_STAGE/" "$DEST_DIR/"
            fi
            while IFS= read -r -d '' f; do
              rel="${f#"$DEST_BASE/"}"; bytes=$(stat -c%s "$f"); sha=$(sha256sum "$f" | awk '{print $1}')
              printf '%s,%s,%s,%s,%s\n' "$SRC" "$RESOLVED_SRC" "$DEST_REL" "${rel#"$DEST_REL/"}" "$bytes" "$sha" >> "$MANIFEST_CSV"
            done < <(find "$DEST_DIR" -type f -print0)
            rm -rf "$TMP_STAGE"
            echo "include_in_iso=${INCLUDE_ISO}" > "$DEST_DIR/.iso.include"
          done
          echo "‚úÖ Manifest generated: $MANIFEST_CSV"

      # === Buildx/QEMU ÏÑ∏ÌåÖ(Î©ÄÌã∞ÏïÑÏπò Í∞ÄÎä• Ïãú ÌôúÏö©, Î∂àÍ∞Ä Ïãú ÏûêÎèô Ìè¥Î∞±) ===
      - name: Setup QEMU
        uses: docker/setup-qemu-action@v3
        with: { platforms: all }

      - name: Setup Buildx (docker-container driver)
        uses: docker/setup-buildx-action@v3
        with:
          install: true
          driver: docker-container

      - name: Docker build + save (Ìï≠ÏÉÅ ÏÑ±Í≥µ)
        shell: bash
        run: |
          set -Eeuo pipefail
          ROOT="workspace/${{ inputs.package_name }}"
          IMG="${{ steps.parse.outputs.image_name }}:${{ steps.parse.outputs.image_tag }}"
          mkdir -p artifacts
          if [[ "${{ inputs.build_docker }}" == "true" ]]; then
            docker build -t "$IMG" "$ROOT"
            docker save "$IMG" | gzip -c > "artifacts/${{ steps.parse.outputs.image_name }}-${{ steps.parse.outputs.image_tag }}.tar.gz"
            echo "‚úÖ image built & saved"
          else
            tar -czf "artifacts/${{ steps.parse.outputs.image_name }}-${{ steps.parse.outputs.image_tag }}.tar.gz" -C "$ROOT" .
            echo "‚úÖ fallback artifact saved"
          fi

      - name: Install Syft & Trivy
        shell: bash
        run: |
          set -Eeuo pipefail
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin || true
          curl -sSfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin || true

      - name: SBOM (dir + image if built)
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p security
          syft scan dir:workspace/${{ inputs.package_name }} -o spdx-json -q > security/pkg-sbom.spdx.json || echo '{}' > security/pkg-sbom.spdx.json
          if [[ "${{ inputs.build_docker }}" == "true" ]]; then
            syft scan ${{ steps.parse.outputs.image_name }}:${{ steps.parse.outputs.image_tag }} -o spdx-json -q > security/image-sbom.spdx.json || echo '{}' > security/image-sbom.spdx.json
          else
            echo '{}' > security/image-sbom.spdx.json
          fi

      - name: Trivy scan (image or folder fallback)
        shell: bash
        run: |
          set -Eeuo pipefail
          if [[ "${{ inputs.build_docker }}" == "true" ]]; then
            trivy image --no-progress --severity HIGH,CRITICAL --format table \
              -o security/image-vuln.txt ${{ steps.parse.outputs.image_name }}:${{ steps.parse.outputs.image_tag }} || true
          else
            trivy fs --no-progress --severity HIGH,CRITICAL --format table \
              -o security/image-vuln.txt workspace/${{ inputs.package_name }} || true
          fi
          echo "‚úÖ vuln scan done"

      - name: Prepare ISO staging
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"; ROOT="workspace/${P}"; STAGE="iso_stage/${P}"
          mkdir -p "$STAGE/config" "$STAGE/pkg" "$STAGE/docs" "$STAGE/extra" "$STAGE/server"
          echo "${{ github.repository }},${{ github.run_id }},${{ github.ref_name }}" > "$STAGE/build_info.csv"
          printf '%s' '${{ inputs.inject_info_json }}' | jq . > "$STAGE/config/inject.json"
          cp -a "$ROOT/dist" "$STAGE/pkg/" || true
          cp -a .github/echo_logs "$STAGE/docs/" || true
          # echo_mass ÌååÏùºÏù¥ Ìï≠ÏÉÅ ÏûàÏúºÎØÄÎ°ú ÏïàÏ†Ñ
          cp -a "$ROOT/echo_mass/perm_apply.sh" "$STAGE/docs/" || true
          [[ -d "$ROOT/extra_manifests" ]] && cp -a "$ROOT/extra_manifests" "$STAGE/docs/" || true
          cp -a "$ROOT/server" "$STAGE/" || true
          if [[ -d "$ROOT" ]]; then
            while IFS= read -r -d '' marker; do
              d="$(dirname "$marker")"; rel="${d#"$ROOT/"}"; mkdir -p "$STAGE/extra/$rel"
              rsync -a "$d/" "$STAGE/extra/$rel/"
            done < <(find "$ROOT" -type f -name ".iso.include" -print0 | xargs -0 grep -l "include_in_iso=true" || true)
          fi
          (cd "$STAGE" && find . -type f -print0 | xargs -0 sha256sum) > "$STAGE/docs/ISO_FILES.sha256"

      - name: Build ISO
        shell: bash
        run: |
          set -Eeuo pipefail
          ISO_NAME="${{ inputs.package_name }}-${{ inputs.package_version }}.iso"
          LABEL="${{ inputs.iso_label }}"; STAGE="iso_stage/${{ inputs.package_name }}"
          mkdir -p artifacts
          if command -v xorriso >/dev/null 2>&1; then
            xorriso -as mkisofs -R -J -V "$LABEL" -o "artifacts/${ISO_NAME}" "$STAGE"
          else
            genisoimage -R -J -V "$LABEL" -o "artifacts/${ISO_NAME}" "$STAGE"
          fi
          (cd artifacts && sha256sum "${ISO_NAME}" > "${ISO_NAME}.sha256" )
          echo "‚úÖ ISO built"

      - name: Compute GHCR semver tags
        id: ghcrtags
        shell: bash
        run: |
          set -Eeuo pipefail
          REPO="${{ steps.parse.outputs.ghcr_repo }}"
          V="${{ inputs.package_version }}"; RI="${{ github.run_id }}"
          MAJOR="${V%%.*}"; MINOR="${V%.*}"
          echo "tags=${REPO}:${V}-${RI},${REPO}:${MAJOR}.${MINOR#${MAJOR}.}-${RI},${REPO}:${MAJOR}-${RI},${REPO}:latest" >> "$GITHUB_OUTPUT"

      - name: Buildx + push GHCR (Î©ÄÌã∞ÏïÑÏπò Í∞ÄÎä• Ïãú push, Î∂àÍ∞Ä Ïãú Îã®Ïùº/Î°úÏª¨ Ìè¥Î∞±)
        shell: bash
        run: |
          set -Eeuo pipefail
          ROOT="workspace/${{ inputs.package_name }}"
          T1="$(echo "${{ steps.ghcrtags.outputs.tags }}"|cut -d, -f1)"
          docker buildx ls || true
          if [[ "${{ inputs.build_docker }}" == "true" ]]; then
            echo "${{ github.token }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin || true
            # Î©ÄÌã∞ÏïÑÏπò ÏãúÎèÑ
            docker buildx build --platform linux/amd64,linux/arm64 \
              -t "$T1" -f "$ROOT/Dockerfile" "$ROOT" --push && OK=1 || OK=0
            if [[ "$OK" -ne 1 ]]; then
              echo "‚ö†Ô∏è multi-arch push not available; single-arch fallback"
              docker buildx build --platform linux/amd64 -t "$T1" -f "$ROOT/Dockerfile" "$ROOT" --load || true
            fi
          else
            echo "‚ÑπÔ∏è build_docker=false; skipping remote push but step completed."
          fi
          echo "‚úÖ GHCR step done"

      - name: Push to Docker Hub (fallback to artifact when no creds)
        shell: bash
        env:
          DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
          DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
        run: |
          set -Eeuo pipefail
          SRC_IMG="${{ steps.parse.outputs.image_name }}:${{ steps.parse.outputs.image_tag }}"
          DEST_REPO="${{ steps.parse.outputs.dh_repo }}"
          DEST_TAG="${{ steps.parse.outputs.dh_tag }}"
          mkdir -p artifacts
          if [[ -n "$DOCKERHUB_USERNAME" && -n "$DOCKERHUB_TOKEN" && "${{ inputs.build_docker }}" == "true" ]]; then
            echo "$DOCKERHUB_TOKEN" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin || true
            docker image inspect "$SRC_IMG" >/dev/null 2>&1 || docker build -t "$SRC_IMG" "workspace/${{ inputs.package_name }}" || true
            docker tag "$SRC_IMG" "$DEST_REPO:$DEST_TAG" || true
            docker push "$DEST_REPO:$DEST_TAG" || echo "‚ö†Ô∏è dockerhub push failed (non-fatal)"
          else
            docker image inspect "$SRC_IMG" >/dev/null 2>&1 && docker save "$SRC_IMG" | gzip -c > "artifacts/dockerhub-fallback-${DEST_REPO//\//_}-${DEST_TAG}.tar.gz" || true
          fi
          echo "‚úÖ DockerHub step done"

      - name: Cosign (Ïó¨Îü¨ Í≤ΩÎ°ú ÏãúÎèÑ + ÏôÑÏ†Ñ Ìè¥Î∞±)
        shell: bash
        env:
          COSIGN_EXPERIMENTAL: "1"
          COSIGN_KEY: ${{ secrets.COSIGN_KEY }}
          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}
        run: |
          set -Eeuo pipefail
          T1="$(echo "${{ steps.ghcrtags.outputs.tags }}"|cut -d, -f1)"
          install_ok=0
          { curl -fsSL https://raw.githubusercontent.com/sigstore/cosign/main/install.sh | sh -s -- -b /usr/local/bin && install_ok=1; } || true
          if [[ "$install_ok" -ne 1 ]]; then
            curl -fsSL -o /usr/local/bin/cosign https://github.com/sigstore/cosign/releases/latest/download/cosign-linux-amd64 || true
            chmod +x /usr/local/bin/cosign || true
            command -v cosign >/dev/null 2>&1 && install_ok=1 || install_ok=0
          fi
          if [[ "${{ inputs.build_docker }}" == "true" && "$install_ok" -eq 1 ]]; then
            if [[ -n "$COSIGN_KEY" ]]; then
              cosign sign --key env://COSIGN_KEY "$T1" || true
              [[ -f security/image-sbom.spdx.json ]] && cosign attest --key env://COSIGN_KEY --predicate security/image-sbom.spdx.json --type spdx "$T1" || true
            else
              cosign sign "$T1" || echo '{"note":"keyless-fallback"}' > security/local-attest.json
            fi
          else
            echo '{"note":"cosign-not-installed-or-no-image"}' > security/local-attest.json
          fi
          echo "‚úÖ cosign step done"

      - name: Generate changelog
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p artifacts
          git fetch --tags --force || true
          PREV_TAG=$(git tag --sort=-creatordate | sed -n '2p')
          git log --pretty=format:"* %h %s (%an)" ${PREV_TAG}..HEAD > artifacts/CHANGELOG.txt || true
          [[ -s artifacts/CHANGELOG.txt ]] || echo "* Initial release" > artifacts/CHANGELOG.txt

      - name: Create GitHub Release (safe-tag)
        uses: softprops/action-gh-release@v2
        with:
          tag_name: v${{ inputs.package_version }}-${{ github.run_id }}
          draft: false
          prerelease: false
          files: |
            artifacts/*.iso
            artifacts/*.sha256
            artifacts/CHANGELOG.txt
            artifacts/*.tar.gz
            security/**
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Deploy (real SSH if secrets/host, else local emulation)
        shell: bash
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SERVER_SSH_KEY }}
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"; ROOT="workspace/${P}"
          HOST="${{ steps.parse.outputs.dep_host }}"; USER="${{ steps.parse.outputs.dep_user }}"
          PORT="${{ steps.parse.outputs.dep_port }}"; DEST="${{ steps.parse.outputs.dep_path }}"
          SVC="${{ steps.parse.outputs.dep_svc }}"; CMD="${{ steps.parse.outputs.dep_cmd }}"; USE_SUDO="${{ steps.parse.outputs.dep_sudo }}"
          if [[ -n "$SSH_PRIVATE_KEY" && -n "$HOST" ]]; then
            mkdir -p ~/.ssh; echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa; chmod 600 ~/.ssh/id_rsa
            ssh -o StrictHostKeyChecking=no -p "$PORT" "$USER@$HOST" "mkdir -p $DEST" || true
            rsync -az -e "ssh -p $PORT -o StrictHostKeyChecking=no" "$ROOT/" "$USER@$HOST:$DEST/" || true
            SUDO_FLAG=""; [[ "$USE_SUDO" == "true" ]] && SUDO_FLAG="SUDO=sudo"
            ssh -o StrictHostKeyChecking=no -p "$PORT" "$USER@$HOST" \
              "cd $DEST && $SUDO_FLAG APP_NAME=${P} DEPLOY_PATH=$DEST START_CMD='$CMD' bash ./server/install_deploy.sh" || true
            ssh -o StrictHostKeyChecking=no -p "$PORT" "$USER@$HOST" "systemctl is-active $SVC || true" || true
          else
            echo "‚ÑπÔ∏è No SSH or host; running local emulation"
            EMU="/tmp/deploy-${P}"; rm -rf "$EMU"; mkdir -p "$EMU"
            rsync -a "$ROOT/" "$EMU/" || true
            SUDO_FLAG=""; [[ "$USE_SUDO" == "true" ]] && SUDO_FLAG="SUDO=sudo"
            (cd "$EMU" && $SUDO_FLAG APP_NAME=${P} DEPLOY_PATH=$EMU START_CMD='$CMD' bash ./server/install_deploy.sh) || true
            echo "active (emulated)" > "$EMU/.service-status"
          fi
          echo "‚úÖ deploy step done"

      - name: Upload artifacts (7d)
        uses: actions/upload-artifact@v4
        with:
          name: echo-image-iso-${{ github.run_id }}
          path: |
            artifacts/**
            workspace/**/dist/**
            .github/echo_logs/**
            security/**
            iso_stage/**/docs/ISO_FILES.sha256
            pip-wheelhouse.tzst
          retention-days: 7
          if-no-files-found: warn
