name: "üêç PyPkg + EchoOps (QA Matrix + Build + ISO + SBOM + Push + Release + Deploy + Caches)"

on:
  workflow_dispatch:
    inputs:
      package_name:
        description: "Ìå®ÌÇ§ÏßÄ Ïù¥Î¶Ñ(PEP8: ÏÜåÎ¨∏Ïûê/Ïà´Ïûê/_Îßå)"
        required: true
        default: "mypkg"
      package_version:
        description: "Ìå®ÌÇ§ÏßÄ Î≤ÑÏ†Ñ (SemVer)"
        required: true
        default: "0.1.0"
      dirs_count:
        description: "ÎåÄÎüâ ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ± Í∞úÏàò"
        required: true
        default: "500"
      iso_label:
        description: "ISO ÎùºÎ≤®(ÏòÅÎ¨∏/Ïà´Ïûê/Ïñ∏ÎçîÏä§ÏΩîÏñ¥)"
        required: true
        default: "ECHO_ISO"
      inject_info_json:
        description: "ISO Ï£ºÏûÖ JSON"
        required: false
        default: "{\"env\":\"dev\",\"team\":\"finops\"}"
      metadata_json:
        description: "Ìå®ÌÇ§ÏßÄ Î©îÌÉÄ(JSON)"
        required: false
        default: "{\"author_name\":\"Your Name\",\"author_email\":\"you@example.com\",\"license_name\":\"MIT\"}"
      image_ref:
        description: "Docker Ïù¥ÎØ∏ÏßÄ (Ïù¥Î¶Ñ:ÌÉúÍ∑∏)"
        required: true
        default: "mypkg-app:latest"
      build_docker:
        description: "Docker Ïù¥ÎØ∏ÏßÄ ÎπåÎìú/Ï†ÄÏû•"
        required: true
        type: boolean
        default: true
      copy_plan_json:
        description: "ÎîîÎ†âÌÜ†Î¶¨ Î≥µÏÇ¨ Í≥ÑÌöç(JSON)"
        required: false
        default: "{\"plans\":[{\"src\":\"samples\",\"dest_rel\":\"extra/samples\",\"include_globs\":[\"**/*\"],\"exclude_globs\":[\"**/.git/**\",\"**/.github/**\"],\"max_mb\":100,\"include_in_iso\":true,\"required\":false}]}"
      advanced_json:
        description: "ÌôïÏû•ÏÑ§Ï†ï(JSON) - ÏóÖÍ∑∏Î†àÏù¥Îìú/Î†àÏßÄÏä§Ìä∏Î¶¨/Î¶¥Î¶¨Ï¶à/Î∞∞Ìè¨/Ìå®ÌÇ§Ïßï Îì±"
        required: false
        default: "{\"upgrade\":{\"all\":false,\"pip_tools\":true,\"sbom_sec\":true},\"packaging\":{\"mode\":\"pip\"},\"ghcr\":{\"enable\":false,\"repo\":\"\",\"tags\":[]},\"dockerhub\":{\"enable\":false,\"repo\":\"\",\"tag\":\"\"},\"release\":{\"enable\":false,\"tag\":\"\",\"draft\":false,\"prerelease\":false},\"server\":{\"enable\":false,\"host\":\"\",\"user\":\"ubuntu\",\"port\":22,\"deploy_path\":\"/opt/mypkg\",\"service_name\":\"mypkg\",\"start_cmd\":\"python -m mypkg\",\"use_sudo\":true},\"base_image\":\"python:3.11-slim\"}"

permissions:
  contents: write
  packages: write
  actions: read
  id-token: write

concurrency:
  group: pypkg-echo-${{ github.ref }}
  cancel-in-progress: true

env:
  TZ: Asia/Seoul
  LOG_DIR: .github/echo_logs
  ECHO_OK: "‚úÖ"
  ECHO_WARN: "‚ö†Ô∏è"
  ECHO_FAIL: "‚ùå"
  DOCKER_BUILDKIT: "1"
  LC_ALL: C.UTF-8
  LANG: C.UTF-8

jobs:
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # ‚ìµ QA Îß§Ìä∏Î¶≠Ïä§ (3.9~3.12): Ï∫êÏãú ‚Üí ÏÑ§Ïπò ‚Üí Î¶∞Ìä∏/ÌÉÄÏûÖ ‚Üí Ïª§Î≤ÑÎ¶¨ÏßÄ ÏûêÎèôÍ∞êÏßÄ ÌÖåÏä§Ìä∏
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  qa-matrix:
    strategy:
      fail-fast: false
      matrix:
        python: ["3.9", "3.10", "3.11", "3.12"]
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Global echo helpers (export BASH_ENV)
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p "$LOG_DIR"
          cat > "$GITHUB_WORKSPACE/.bashenv" <<'SH'
          ECHO_OK="${ECHO_OK:-‚úÖ}"; ECHO_WARN="${ECHO_WARN:-‚ö†Ô∏è}"; ECHO_FAIL="${ECHO_FAIL:-‚ùå}"
          LOG_DIR="${LOG_DIR:-.github/echo_logs}"; mkdir -p "$LOG_DIR"
          SAFE_LOG="${SAFE_LOG:-${LOG_DIR}/qa-$(date +%Y%m%d%H%M%S).log}"
          echoe(){ printf '%s %s\n' "$ECHO_OK" "$*"; }
          warn(){  printf '%s %s\n' "$ECHO_WARN" "$*"; }
          fail(){  printf '%s %s\n' "$ECHO_FAIL" "$*"; }
          logf(){  printf '%s\n' "$*" | tee -a "$SAFE_LOG"; }
          SH
          echo "BASH_ENV=$GITHUB_WORKSPACE/.bashenv" >> "$GITHUB_ENV"

      - name: Setup Python (${{ matrix.python }})
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Prep wheelhouse + cache (build/pytest/pytest-cov/coverage/mypy/ruff)
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p .pip-wheelhouse
          printf "build\npytest\npytest-cov\ncoverage\nmypy\nruff\n" > .req.txt
          pip wheel -w .pip-wheelhouse -r .req.txt || true
          echo "‚úÖ wheelhouse prebuilt"

      - name: Cache wheelhouse
        uses: actions/cache@v4
        with:
          path: .pip-wheelhouse
          key: wheelhouse-${{ runner.os }}-${{ matrix.python }}-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            wheelhouse-${{ runner.os }}-${{ matrix.python }}-
            wheelhouse-${{ runner.os }}-

      - name: Install QA deps (prefer wheelhouse)
        shell: bash
        run: |
          set -Eeuo pipefail
          if ls .pip-wheelhouse/*.whl >/dev/null 2>&1; then
            pip install --no-index --find-links .pip-wheelhouse build pytest pytest-cov coverage mypy ruff
          else
            pip install build pytest pytest-cov coverage mypy ruff
          fi
          echo "‚úÖ QA deps ready"

      - name: Generate minimal package skeleton for QA (src layout)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ github.event.inputs.package_name || 'mypkg' }}"
          V="${{ github.event.inputs.package_version || '0.1.0' }}"
          ROOT="workspace/${P}"
          PKG_DIR="$ROOT/src/${P}"
          TEST_DIR="$ROOT/tests"
          mkdir -p "$PKG_DIR" "$TEST_DIR"
          cat > "$PKG_DIR/__init__.py" <<PY
          __all__ = ["hello"]
          __version__ = "${V}"
          def hello(name: str = "World") -> str:
              return f"Hello, {name}!"
          PY
          cat > "$TEST_DIR/test_hello.py" <<'PY'
          import importlib
          import os
          import sys
          here = os.path.dirname(__file__)
          root = os.path.abspath(os.path.join(here, "..", "src"))
          if root not in sys.path:
              sys.path.insert(0, root)
          pkg = importlib.import_module("mypkg")
          def test_hello() -> None:
              assert pkg.hello("Echo") == "Hello, Echo!"
          PY
          echo "‚úÖ QA skeleton ready at $ROOT"

      - name: Lint & Type check
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ github.event.inputs.package_name || 'mypkg' }}"
          # Í≥†Ïùò Ïã§Ìå® Î∞©ÏßÄ: ÏûêÎèôÏàòÏ†ï ÌõÑ, Í≤ΩÍ≥†Îßå Ï∂úÎ†•
          ruff check --fix "workspace/${P}" || true
          ruff check --exit-zero "workspace/${P}"
          mypy "workspace/${P}/src" || echo "‚ö†Ô∏è mypy warnings (non-fatal)"

      - name: Test with coverage (auto-detect pytest-cov)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ github.event.inputs.package_name || 'mypkg' }}"
          cd "workspace/${P}"
          mkdir -p ../test-results
          if pytest --help | grep -q -- "--cov[= ]"; then
            pytest -q --junitxml=../test-results/junit-${{ matrix.python }}.xml \
                   --cov="${P}" --cov-report=xml:../test-results/coverage-${{ matrix.python }}.xml
            echo "‚úÖ pytest with coverage ok (${{ matrix.python }})"
          else
            echo "‚ö†Ô∏è pytest-cov not detected; running without coverage"
            pytest -q --junitxml=../test-results/junit-${{ matrix.python }}.xml
            echo "‚úÖ pytest ok (${{ matrix.python }})"
          fi

      - name: Upload QA artifacts
        uses: actions/upload-artifact@v4
        with:
          name: qa-reports-${{ github.run_id }}-${{ matrix.python }}
          path: |
            .github/echo_logs/**
            workspace/**/test-results/*.xml
          if-no-files-found: warn
          retention-days: 7

      - name: Cleanup caches (QA)
        if: ${{ always() }}
        shell: bash
        run: |
          set -Eeuo pipefail
          docker system prune -af || true
          sudo rm -rf /var/lib/apt/lists/* || true
          echo "‚úÖ QA cleanup done"

  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # ‚ì∂ Î©îÏù∏: Ï∫êÏãú‚ÜíÏä§ÏºàÎ†àÌÜ§‚ÜíÌÖåÏä§Ìä∏‚ÜíÎπåÎìú‚ÜíÎåÄÎüâÏÉùÏÑ±‚ÜíCopyPlan‚ÜíSBOM/Ï∑®ÏïΩÏ†ê‚ÜíISO
  #          ‚Üí (ÏÑ†ÌÉù) GHCR/DockerHub Ìë∏Ïãú + cosign ‚Üí (ÏÑ†ÌÉù) Release ‚Üí (ÏÑ†ÌÉù) Î∞∞Ìè¨
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  all-in-one:
    needs: [qa-matrix]
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Global echo helpers (export BASH_ENV)
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p "$LOG_DIR"
          cat > "$GITHUB_WORKSPACE/.bashenv" <<'SH'
          ECHO_OK="${ECHO_OK:-‚úÖ}"; ECHO_WARN="${ECHO_WARN:-‚ö†Ô∏è}"; ECHO_FAIL="${ECHO_FAIL:-‚ùå}"
          LOG_DIR="${LOG_DIR:-.github/echo_logs}"; mkdir -p "$LOG_DIR"
          SAFE_LOG="${SAFE_LOG:-${LOG_DIR}/run-$(date +%Y%m%d%H%M%S).log}"
          echoe(){ printf '%s %s\n' "$ECHO_OK" "$*"; }
          warn(){  printf '%s %s\n' "$ECHO_WARN" "$*"; }
          fail(){  printf '%s %s\n' "$ECHO_FAIL" "$*"; }
          logf(){  printf '%s\n' "$*" | tee -a "$SAFE_LOG"; }
          SH
          echo "BASH_ENV=$GITHUB_WORKSPACE/.bashenv" >> "$GITHUB_ENV"

      - name: Source echo helpers (ensure)
        shell: bash
        run: |
          set -Eeuo pipefail
          source "$GITHUB_WORKSPACE/.bashenv"
          echoe "helpers sourced"; logf "helpers ready"

      - name: Better fail trap (tail last logs on error)
        shell: bash
        run: |
          set -Eeuo pipefail
          trap 'echo "‚ùå Failed at line $LINENO"; tail -n 200 ${LOG_DIR}/run-* 2>/dev/null || true' ERR
          echo "‚úÖ trap ready"

      - name: Parse inputs ‚Üí OUTPUT
        id: parse
        shell: bash
        run: |
          set -Eeuo pipefail
          MJ='${{ inputs.metadata_json }}'
          A_NAME=$(printf '%s' "$MJ" | jq -r '.author_name // "Your Name"')
          A_EMAIL=$(printf '%s' "$MJ" | jq -r '.author_email // "you@example.com"')
          L_NAME=$(printf '%s' "$MJ" | jq -r '.license_name // "MIT"')
          IMG='${{ inputs.image_ref }}'
          if [[ "$IMG" == *:* ]]; then IMG_NAME="${IMG%%:*}"; IMG_TAG="${IMG##*:}"; else IMG_NAME="$IMG"; IMG_TAG="latest"; fi
          ADV='${{ inputs.advanced_json }}'
          printf '%s' "$ADV" | jq . >/dev/null
          U_ALL=$(printf '%s' "$ADV" | jq -r '.upgrade.all // false')
          U_PIP=$(printf '%s' "$ADV" | jq -r '.upgrade.pip_tools // true')
          U_SEC=$(printf '%s' "$ADV" | jq -r '.upgrade.sbom_sec // true')
          PKG_MODE=$(printf '%s' "$ADV" | jq -r '.packaging.mode // "pip"')
          BASE_IMG=$(printf '%s' "$ADV" | jq -r '.base_image // "python:3.11-slim"')
          GHCR_ENABLE=$(printf '%s' "$ADV" | jq -r '.ghcr.enable // false')
          GHCR_REPO=$(printf '%s' "$ADV" | jq -r '.ghcr.repo // ""')
          DH_ENABLE=$(printf '%s' "$ADV" | jq -r '.dockerhub.enable // false')
          DH_REPO=$(printf '%s' "$ADV" | jq -r '.dockerhub.repo // ""')
          DH_TAG=$(printf '%s' "$ADV" | jq -r '.dockerhub.tag // ""')
          REL_ENABLE=$(printf '%s' "$ADV" | jq -r '.release.enable // false')
          REL_TAG=$(printf '%s' "$ADV" | jq -r '.release.tag // ""')
          REL_DRAFT=$(printf '%s' "$ADV" | jq -r '.release.draft // false')
          REL_PRE=$(printf '%s' "$ADV" | jq -r '.release.prerelease // false')
          DEP_ENABLE=$(printf '%s' "$ADV" | jq -r '.server.enable // false')
          DEP_HOST=$(printf '%s' "$ADV" | jq -r '.server.host // ""')
          DEP_USER=$(printf '%s' "$ADV" | jq -r '.server.user // "ubuntu"')
          DEP_PORT=$(printf '%s' "$ADV" | jq -r '.server.port // 22')
          DEP_PATH=$(printf '%s' "$ADV" | jq -r '.server.deploy_path // "/opt/mypkg"')
          DEP_SVC=$(printf '%s' "$ADV" | jq -r '.server.service_name // "mypkg"')
          DEP_CMD=$(printf '%s' "$ADV" | jq -r '.server.start_cmd // "python -m mypkg"')
          DEP_SUDO=$(printf '%s' "$ADV" | jq -r '.server.use_sudo // true')
          {
            echo "author_name=$A_NAME"
            echo "author_email=$A_EMAIL"
            echo "license_name=$L_NAME"
            echo "image_name=$IMG_NAME"
            echo "image_tag=$IMG_TAG"
            echo "pkg_mode=$PKG_MODE"
            echo "base_image=$BASE_IMG"
            echo "upgrade_all=$U_ALL"
            echo "upgrade_pip=$U_PIP"
            echo "upgrade_sec=$U_SEC"
            echo "ghcr_enable=$GHCR_ENABLE"
            echo "ghcr_repo=$GHCR_REPO"
            echo "dh_enable=$DH_ENABLE"
            echo "dh_repo=$DH_REPO"
            echo "dh_tag=$DH_TAG"
            echo "rel_enable=$REL_ENABLE"
            echo "rel_tag=$REL_TAG"
            echo "rel_draft=$REL_DRAFT"
            echo "rel_prerelease=$REL_PRE"
            echo "dep_enable=$DEP_ENABLE"
            echo "dep_host=$DEP_HOST"
            echo "dep_user=$DEP_USER"
            echo "dep_port=$DEP_PORT"
            echo "dep_path=$DEP_PATH"
            echo "dep_svc=$DEP_SVC"
            echo "dep_cmd=$DEP_CMD"
            echo "dep_sudo=$DEP_SUDO"
          } | tee -a "$LOG_DIR/parsed_inputs.env"
          # export to outputs
          while IFS='=' read -r k v; do
            [[ -n "$k" ]] && echo "$k=$v" >> "$GITHUB_OUTPUT"
          done < "$LOG_DIR/parsed_inputs.env"

      - name: Validate inputs
        shell: bash
        run: |
          set -Eeuo pipefail
          err(){ echo "‚ùå $*"; exit 1; }
          [[ "${{ inputs.package_name }}" =~ ^[a-z0-9_]+$ ]] || err "package_name: ÏÜåÎ¨∏Ïûê/Ïà´Ïûê/_ Îßå ÌóàÏö©"
          [[ "${{ inputs.package_version }}" =~ ^[0-9]+\.[0-9]+\.[0-9]+(-[0-9A-Za-z\.-]+)?$ ]] || err "package_version: SemVer ÌïÑÏöî"
          [[ "${{ inputs.image_ref }}" =~ ^[a-z0-9._/-]+(:[a-zA-Z0-9._-]+)?$ ]] || err "image_ref ÌòïÏãù Ïò§Î•ò"
          if [[ "${{ steps.parse.outputs.rel_enable }}" == "true" ]]; then
            [[ "${{ steps.parse.outputs.rel_tag }}" =~ ^v?[0-9]+\.[0-9]+\.[0-9]+$ ]] || err "rel_tag: vX.Y.Z ÌïÑÏöî"
          fi
          echo "‚úÖ input validation passed"

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Pip cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-

      - name: Wheelhouse cache
        uses: actions/cache@v4
        with:
          path: .pip-wheelhouse
          key: wheelhouse-${{ runner.os }}-main-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            wheelhouse-${{ runner.os }}-main-

      - name: (Optional) Upgrade toolchain
        if: ${{ steps.parse.outputs.upgrade_all == 'true' || steps.parse.outputs.upgrade_pip == 'true' }}
        shell: bash
        run: |
          set -Eeuo pipefail
          if command -v sudo >/dev/null 2>&1; then SUDO="sudo"; else SUDO=""; fi
          $SUDO apt-get update -y
          $SUDO apt-get install -y --no-install-recommends git jq rsync xorriso genisoimage dosfstools python3-venv python3-pip python3-setuptools python3-wheel
          python3 -m pip install --upgrade pip
          python3 -m pip install --upgrade build pytest pytest-cov coverage ruff mypy
          echo "‚úÖ upgraded base toolchain"

      - name: Create Python package skeleton (src layout + server)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          V="${{ inputs.package_version }}"
          A="${{ steps.parse.outputs.author_name }}"
          E="${{ steps.parse.outputs.author_email }}"
          L="${{ steps.parse.outputs.license_name }}"
          BASE="${{ steps.parse.outputs.base_image }}"
          ROOT="workspace/${P}"
          PKG_DIR="$ROOT/src/${P}"
          TEST_DIR="$ROOT/tests"
          DOC_DIR="$ROOT/docs"
          mkdir -p "$PKG_DIR" "$TEST_DIR" "$DOC_DIR"
          cat > "$ROOT/pyproject.toml" <<PYT
          [build-system]
          requires = ["setuptools>=68", "wheel"]
          build-backend = "setuptools.build_meta"
          [project]
          name = "${P}"
          version = "${V}"
          description = "Auto-generated package with EchoOps"
          authors = [{ name="${A}", email="${E}"}]
          license = { text="${L}" }
          readme = "README.md"
          requires-python = ">=3.9"
          classifiers = [
            "Programming Language :: Python :: 3",
            "License :: OSI Approved :: MIT License"
          ]
          [tool.setuptools.packages.find]
          where = ["src"]
          PYT
          cat > "$ROOT/README.md" <<'MD'
          # Auto Generated Python Package
          - EchoOps generated: Dockerfile, ISO artifacts, SBOM, QA, caches.
          MD
          cat > "$PKG_DIR/__init__.py" <<PY
          __all__ = ["hello"]
          __version__ = "${V}"
          def hello(name: str = "World") -> str:
              return f"Hello, {name}!"
          PY
          cat > "$TEST_DIR/test_hello.py" <<'PY'
          import importlib
          import os
          import sys
          here = os.path.dirname(__file__)
          root = os.path.abspath(os.path.join(here, "..", "src"))
          if root not in sys.path:
              sys.path.insert(0, root)
          m = importlib.import_module("mypkg")
          def test_hello() -> None:
              assert m.hello("Echo") == "Hello, Echo!"
          PY
          cat > "$ROOT/Dockerfile" <<DOCKER
          FROM ${BASE}
          WORKDIR /app
          COPY . /app
          RUN pip install --no-cache-dir .
          CMD ["python","-c","import importlib,sys,os,glob;root=os.path.abspath('src');sys.path.insert(0,root) if root not in sys.path else None;mods=[d for d in glob.glob(os.path.join(root,'*')) if os.path.isdir(d)];m=importlib.import_module(os.path.basename(mods[0])) if mods else None;print(m.hello('Docker')) if m and hasattr(m,'hello') else print('ok')"]
          DOCKER
          mkdir -p "$ROOT/server"
          cat > "$ROOT/server/install_deploy.sh" <<'SH'
          #!/usr/bin/env bash
          set -Eeuo pipefail
          SUDO=${SUDO:-sudo}
          APP_NAME="${APP_NAME:-__APP__}"
          DEPLOY_PATH="${DEPLOY_PATH:-/opt/__APP__}"
          START_CMD="${START_CMD:-python -m __APP__}"
          $SUDO mkdir -p "$DEPLOY_PATH"
          rsync -a ./ "$DEPLOY_PATH/"
          $SUDO python3 -m venv "$DEPLOY_PATH/.venv"
          $SUDO bash -lc "source '$DEPLOY_PATH/.venv/bin/activate' && pip install --upgrade pip && pip install ."
          UNIT="/etc/systemd/system/__APP__.service"
          cat | $SUDO tee "$UNIT" >/dev/null <<EOF
          [Unit]
          Description=__APP__ Service
          After=network.target
          [Service]
          Type=simple
          WorkingDirectory=$DEPLOY_PATH
          ExecStart=$DEPLOY_PATH/.venv/bin/${START_CMD}
          Restart=on-failure
          [Install]
          WantedBy=multi-user.target
          EOF
          $SUDO systemctl daemon-reload
          $SUDO systemctl enable __APP__.service
          $SUDO systemctl restart __APP__.service
          SH
          sed -i "s/__APP__/${P}/g" "$ROOT/server/install_deploy.sh"
          chmod +x "$ROOT/server/install_deploy.sh"
          chmod -R u+rwX,go+rX "$ROOT"
          echo "‚úÖ skeleton ready"

      - name: Install test deps
        shell: bash
        run: |
          set -Eeuo pipefail
          python -m pip install --upgrade pip
          pip install build pytest pytest-cov coverage ruff mypy

      - name: Run unit tests (auto-cov)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          cd "workspace/${P}"
          export PYTHONPATH="$PWD/src${PYTHONPATH:+:$PYTHONPATH}"
          mkdir -p ../test-results
          if pytest --help | grep -q -- "--cov[= ]"; then
            pytest -q --junitxml=../test-results/junit.xml --cov="${P}" --cov-report=xml:../test-results/coverage.xml
          else
            pytest -q --junitxml=../test-results/junit.xml
          fi
          echo "‚úÖ tests passed"

      - name: Lint (ruff) + Type check (mypy)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          ruff check --fix "workspace/${P}" || true
          ruff check --exit-zero "workspace/${P}"
          mypy "workspace/${P}/src" || echo "‚ö†Ô∏è mypy warnings (non-fatal)"

      - name: Build dist (pip/poetry/conda)
        id: buildpkg
        shell: bash
        run: |
          set -Eeuo pipefail
          MODE="${{ steps.parse.outputs.pkg_mode }}"
          P="${{ inputs.package_name }}"
          ROOT="workspace/${P}"
          case "$MODE" in
            poetry)
              python3 -m pip install --upgrade pip poetry build
              (cd "$ROOT" && poetry build)
              ;;
            conda)
              sudo apt-get update -y && sudo apt-get install -y wget bzip2
              MINI="$HOME/miniconda"
              wget -qO ~/miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
              bash ~/miniconda.sh -b -p "$MINI"
              source "$MINI/etc/profile.d/conda.sh"
              conda create -y -n "${P}" python=3.11
              conda activate "${P}"
              pip install --upgrade pip
              (cd "$ROOT" && pip install .)
              pip install conda-pack
              mkdir -p "$ROOT/dist"
              conda pack -n "${P}" -o "$ROOT/dist/${P}-env.tar.gz"
              ;;
            *)
              python3 -m pip install --upgrade pip build
              python3 -m build "$ROOT"
              ;;
          esac
          ls -al "$ROOT/dist"

      - name: Massive directory generation (except #11)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          COUNT="${{ inputs.dirs_count }}"
          BASE="workspace/${P}/echo_mass"
          mkdir -p "$BASE"
          cat > "$BASE/perm_apply.sh" <<'SH'
          #!/usr/bin/env bash
          set -Eeuo pipefail
          LOG_DIR="${LOG_DIR:-.github/echo_logs}"; mkdir -p "$LOG_DIR"
          OUT="$LOG_DIR/perm-$(date +%Y%m%d%H%M%S).log"
          echo "perm started: $(date)" | tee -a "$OUT"
          for d in "$@"; do
            mkdir -p "$d"; chmod 755 "$d"
            printf 'ECHO %s %s\n' "$(date +%Y-%m-%dT%H:%M:%S)" "$d" | tee -a "$OUT"
            echo "ok" > "$d/.echo.ok"
          done
          echo "done: $(date)" | tee -a "$OUT"
          SH
          chmod +x "$BASE/perm_apply.sh"
          mapfile -t DLIST < <(seq -w 1 "$COUNT" | awk '$1!=11{print}')
          DLIST=("${DLIST[@]/#/${BASE}/dir_}")
          "${BASE}/perm_apply.sh" "${DLIST[@]}"
          echo "‚úÖ generated ${#DLIST[@]} dirs"

      - name: Ensure sources for copy plan
        shell: bash
        run: |
          set -Eeuo pipefail
          if ! [[ -d samples ]]; then
            mkdir -p samples
            echo "dummy" > samples/README.txt
            echo "‚ö†Ô∏è created temp samples/"
          fi
          echo "‚úÖ sources ensured"

      - name: Copy by copy_plan_json (manifest + checksums)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          ROOT="workspace/${P}"
          PLAN_FILE="copy_plan.json"
          printf '%s' '${{ inputs.copy_plan_json }}' > "$PLAN_FILE"
          [[ -f "$PLAN_FILE" ]] || { echo "‚ö†Ô∏è copy_plan.json not found, skip"; exit 0; }
          mkdir -p "$ROOT/extra_manifests"
          MAN="$ROOT/extra_manifests/manifest-$(date +%Y%m%d%H%M%S).csv"
          echo "src,resolved_src,dest_rel,relpath,bytes,sha256" > "$MAN"
          nf(){ command -v numfmt >/dev/null 2>&1 && numfmt --to=iec "$1" || echo "$1 bytes"; }
          COUNT_PLANS=$(jq -r '.plans | length' "$PLAN_FILE")
          for i in $(seq 0 $((COUNT_PLANS-1))); do
            SRC=$(jq -r ".plans[$i].src" "$PLAN_FILE")
            DEST_REL=$(jq -r ".plans[$i].dest_rel // \"extra\"" "$PLAN_FILE")
            MAX_MB=$(jq -r ".plans[$i].max_mb // 100" "$PLAN_FILE")
            INCLUDE_ISO=$(jq -r ".plans[$i].include_in_iso // true" "$PLAN_FILE")
            REQUIRED=$(jq -r ".plans[$i].required // false" "$PLAN_FILE")
            mapfile -t INCS < <(jq -r ".plans[$i].include_globs[]?" "$PLAN_FILE")
            mapfile -t EXCS < <(jq -r ".plans[$i].exclude_globs[]?" "$PLAN_FILE")
            RES=""; [[ -d "$SRC" ]] && RES="$SRC"
            [[ -z "$RES" && -d "$GITHUB_WORKSPACE/$SRC" ]] && RES="$GITHUB_WORKSPACE/$SRC"
            [[ -z "$RES" && -d "$ROOT/$SRC" ]] && RES="$ROOT/$SRC"
            if [[ -z "$RES" ]]; then
              [[ "$REQUIRED" == "true" ]] && { echo "‚ùå required src missing: $SRC"; exit 1; }
              echo "‚ö†Ô∏è skip src missing: $SRC"; continue
            fi
            DEST="$ROOT/$DEST_REL"; mkdir -p "$DEST"
            RSYNC=(-a --delete --prune-empty-dirs); for p in "${INCS[@]}"; do RSYNC+=(--include "$p"); done
            for p in "${EXCS[@]}"; do RSYNC+=(--exclude "$p"); done
            RSYNC+=(--exclude '.git/' --exclude '.github/' --include '*/' --exclude '*')
            TMP="$(mktemp -d)"; rsync "${RSYNC[@]}" "$RES/" "$TMP/"
            TB=$(du -sb "$TMP" | awk '{print $1}'); LIM=$((MAX_MB*1024*1024))
            if (( TB > LIM )); then
              echo "‚ö†Ô∏è size exceed: $(nf "$TB") > $(nf "$LIM")"
              mkdir -p "$DEST"; REMAIN=$LIM
              mapfile -t FILES < <(find "$TMP" -type f -printf '%T@ %p\n' | sort -nr | awk '{sub($1 FS,""); print}')
              for f in "${FILES[@]}"; do
                sz=$(stat -c%s "$f"); (( sz <= REMAIN )) || continue
                rel="${f#"$TMP/"}"; mkdir -p "$DEST/$(dirname "$rel")"; cp -a "$f" "$DEST/$rel"; REMAIN=$((REMAIN-sz))
              done
            else
              rsync -a --delete "$TMP/" "$DEST/"
            fi
            if [[ -d "$DEST" ]]; then
              while IFS= read -r -d '' f; do
                rel="${f#"$ROOT/"}"; bytes=$(stat -c%s "$f"); sha=$(sha256sum "$f" | awk '{print $1}')
                printf '%s,%s,%s,%s,%s\n' "$SRC" "$RES" "$DEST_REL" "${rel#"$DEST_REL/"}" "$bytes" "$sha" >> "$MAN"
              done < <(find "$DEST" -type f -print0)
            fi
            rm -rf "$TMP"
            echo "include_in_iso=$([[ "$INCLUDE_ISO" == "true" ]] && echo true || echo false)" > "$DEST/.iso.include"
            echo "plan[$i] done -> $DEST"
          done
          echo "‚úÖ Manifest generated: $MAN"

      - name: Final pip tool upgrade before docker (optional)
        if: ${{ inputs.build_docker == true && (steps.parse.outputs.upgrade_all == 'true' || steps.parse.outputs.upgrade_pip == 'true') }}
        shell: bash
        run: |
          set -Eeuo pipefail
          python3 -m pip install --upgrade pip setuptools wheel build
          echo "‚úÖ final tool upgrade done"

      - name: Docker build + save (single-arch local)
        if: ${{ inputs.build_docker == true }}
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          ROOT="workspace/${P}"
          IMG="${{ steps.parse.outputs.image_name }}:${{ steps.parse.outputs.image_tag }}"
          docker build -t "$IMG" "$ROOT"
          mkdir -p artifacts
          docker save "$IMG" | gzip -c > "artifacts/${{ steps.parse.outputs.image_name }}-${{ steps.parse.outputs.image_tag }}.tar.gz"
          echo "‚úÖ image built & saved"

      - name: Install/Upgrade Syft & Trivy (SBOM/Sec)
        if: ${{ steps.parse.outputs.upgrade_all == 'true' || steps.parse.outputs.upgrade_sec == 'true' || inputs.build_docker == true }}
        shell: bash
        run: |
          set -Eeuo pipefail
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin
          curl -sSfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
          echo "‚úÖ Syft/Trivy ready"

      - name: Generate SBOMs (pkg & image)
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p security
          syft scan dir:workspace/${{ inputs.package_name }} -o spdx-json > security/pkg-sbom.spdx.json || syft packages dir:workspace/${{ inputs.package_name }} -o spdx-json > security/pkg-sbom.spdx.json
          if [[ "${{ inputs.build_docker }}" == "true" ]]; then
            syft ${{ steps.parse.outputs.image_name }}:${{ steps.parse.outputs.image_tag }} -o spdx-json > security/image-sbom.spdx.json || true
          fi

      - name: Trivy vuln scan (fail on HIGH+)
        if: ${{ inputs.build_docker == true }}
        shell: bash
        run: |
          set -Eeuo pipefail
          trivy image --no-progress --severity HIGH,CRITICAL --exit-code 1 \
            ${{ steps.parse.outputs.image_name }}:${{ steps.parse.outputs.image_tag }} || {
              echo "‚ùå HIGH/CRITICAL vulnerabilities found"; exit 1; }

      - name: Prepare ISO staging
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          ROOT="workspace/${P}"
          STAGE="iso_stage/${P}"
          mkdir -p "$STAGE/config" "$STAGE/pkg" "$STAGE/docs" "$STAGE/extra" "$STAGE/server"
          echo "${{ github.repository }},${{ github.run_id }},${{ github.ref_name }}" > "$STAGE/build_info.csv"
          printf '%s' '${{ inputs.inject_info_json }}' | jq . > "$STAGE/config/inject.json"
          cp -a "$ROOT/dist" "$STAGE/pkg/" || true
          cp -a .github/echo_logs "$STAGE/docs/" || true
          cp -a "$ROOT/echo_mass/perm_apply.sh" "$STAGE/docs/" || echo "‚ö†Ô∏è no perm_apply.sh"
          [[ -d "$ROOT/extra_manifests" ]] && cp -a "$ROOT/extra_manifests" "$STAGE/docs/" || true
          cp -a "$ROOT/server" "$STAGE/" || true
          if [[ -d "$ROOT" ]]; then
            while IFS= read -r -d '' marker; do
              d="$(dirname "$marker")"; rel="${d#"$ROOT/"}"
              mkdir -p "$STAGE/extra/$rel"
              rsync -a "$d/" "$STAGE/extra/$rel/"
            done < <(find "$ROOT" -type f -name ".iso.include" -print0 | xargs -0 grep -l "include_in_iso=true" || true)
          fi
          (cd "$STAGE" && find . -type f -print0 | xargs -0 sha256sum) > "$STAGE/docs/ISO_FILES.sha256"
          cp -a security/*.json "$STAGE/docs/" 2>/dev/null || true
          echo "‚úÖ ISO staging ready"

      - name: Build ISO (+ sha256)
        shell: bash
        run: |
          set -Eeuo pipefail
          ISO="${{ inputs.package_name }}-${{ inputs.package_version }}.iso"
          LABEL="${{ inputs.iso_label }}"
          STAGE="iso_stage/${{ inputs.package_name }}"
          mkdir -p artifacts
          if command -v xorriso >/dev/null 2>&1; then
            xorriso -as mkisofs -R -J -V "$LABEL" -o "artifacts/${ISO}" "$STAGE"
          else
            genisoimage -R -J -V "$LABEL" -o "artifacts/${ISO}" "$STAGE"
          fi
          (cd artifacts && sha256sum "${ISO}" > "${ISO}.sha256")
          echo "‚úÖ ISO built"

      # ‚îÄ‚îÄ GHCR Î©ÄÌã∞ÏïÑÌÇ§ (ÏòµÏÖò) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Set up QEMU
        if: ${{ inputs.build_docker == true && steps.parse.outputs.ghcr_enable == 'true' }}
        uses: docker/setup-qemu-action@v3

      - name: Set up Buildx
        if: ${{ inputs.build_docker == true && steps.parse.outputs.ghcr_enable == 'true' }}
        uses: docker/setup-buildx-action@v3
        with:
          driver: docker-container

      - name: Buildx cache
        if: ${{ inputs.build_docker == true && steps.parse.outputs.ghcr_enable == 'true' }}
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: buildx-${{ github.ref }}-${{ github.sha }}
          restore-keys: |
            buildx-${{ github.ref }}-
            buildx-

      - name: Compute GHCR tags
        id: ghcrtags
        if: ${{ inputs.build_docker == true && steps.parse.outputs.ghcr_enable == 'true' }}
        shell: bash
        run: |
          set -Eeuo pipefail
          REPO="${{ steps.parse.outputs.ghcr_repo }}"
          V="${{ inputs.package_version }}"
          RUN="${{ github.run_id }}"
          MAJOR="${V%%.*}"
          MINOR="${V%.*}"
          TAGS="${REPO}:${V}-${RUN},${REPO}:${MAJOR}.${MINOR#${MAJOR}.}-${RUN},${REPO}:${MAJOR}-${RUN},${REPO}:latest"
          echo "tags=${TAGS}" >> "$GITHUB_OUTPUT"
          echo "Computed tags: ${TAGS}"

      - name: Login to GHCR
        if: ${{ inputs.build_docker == true && steps.parse.outputs.ghcr_enable == 'true' }}
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build multi-arch and push (GHCR)
        if: ${{ inputs.build_docker == true && steps.parse.outputs.ghcr_enable == 'true' }}
        uses: docker/build-push-action@v6
        with:
          context: workspace/${{ inputs.package_name }}
          file: workspace/${{ inputs.package_name }}/Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.ghcrtags.outputs.tags }}
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache,mode=max

      # ‚îÄ‚îÄ cosign: keyless or key-based (Îü∞ÌÉÄÏûÑ Ï≤¥ÌÅ¨) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Cosign sign (images & ISO checksums)
        shell: bash
        env:
          COSIGN_EXPERIMENTAL: "1"
          COSIGN_KEY: ${{ secrets.COSIGN_KEY }}
          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}
        run: |
          set -Eeuo pipefail
          curl -sSfL https://raw.githubusercontent.com/sigstore/cosign/main/install.sh | sh -s -- -b /usr/local/bin
          # Ïù¥ÎØ∏ÏßÄ ÏÑúÎ™Ö (GHCR ÏÇ¨Ïö© Ïãú)
          if [[ "${{ steps.parse.outputs.ghcr_enable }}" == "true" && "${{ inputs.build_docker }}" == "true" ]]; then
            IFS=',' read -r -a TAGS <<< "${{ steps.ghcrtags.outputs.tags }}"
            for t in "${TAGS[@]}"; do
              if [[ -n "${COSIGN_KEY}" && -n "${COSIGN_PASSWORD}" ]]; then
                cosign sign --key env://COSIGN_KEY "$t"
              else
                cosign sign "$t"
              fi
            done
            if [[ -f security/image-sbom.spdx.json ]]; then
              if [[ -n "${COSIGN_KEY}" && -n "${COSIGN_PASSWORD}" ]]; then
                cosign attest --key env://COSIGN_KEY --predicate security/image-sbom.spdx.json --type spdx "${TAGS[0]}"
              else
                cosign attest --predicate security/image-sbom.spdx.json --type spdx "${TAGS[0]}"
              fi
            fi
          fi
          # ISO Ï≤¥ÌÅ¨ÏÑ¨ ÏÑúÎ™Ö(ÌÇ§ ÏûàÏùÑ Îïå)
          if ls artifacts/*.iso.sha256 >/dev/null 2>&1 && [[ -n "${COSIGN_KEY}" && -n "${COSIGN_PASSWORD}" ]]; then
            cosign sign-blob --key env://COSIGN_KEY artifacts/*.iso.sha256 > artifacts/ISO_SUMS.sig
          fi
          echo "‚úÖ cosign done"

      # ‚îÄ‚îÄ Docker Hub (ÏòµÏÖò) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Push image to Docker Hub (optional)
        if: ${{ inputs.build_docker == true && steps.parse.outputs.dh_enable == 'true' }}
        shell: bash
        env:
          DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
          DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
        run: |
          set -Eeuo pipefail
          SRC_IMG="${{ steps.parse.outputs.image_name }}:${{ steps.parse.outputs.image_tag }}"
          DEST_REPO="${{ steps.parse.outputs.dh_repo }}"
          DEST_TAG="${{ steps.parse.outputs.dh_tag || steps.parse.outputs.image_tag }}"
          if [[ -z "$DOCKERHUB_USERNAME" || -z "$DOCKERHUB_TOKEN" || -z "$DEST_REPO" ]]; then
            echo "‚ö†Ô∏è DockerHub creds/repo missing; exporting tar fallback"
            mkdir -p artifacts
            docker save "$SRC_IMG" | gzip -c > "artifacts/${{ steps.parse.outputs.image_name }}-${{ steps.parse.outputs.image_tag }}.tar.gz"
            exit 0
          fi
          echo "$DOCKERHUB_TOKEN" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin
          docker tag "$SRC_IMG" "$DEST_REPO:$DEST_TAG"
          docker push "$DEST_REPO:$DEST_TAG"
          echo "‚úÖ pushed to Docker Hub: $DEST_REPO:$DEST_TAG"

      # ‚îÄ‚îÄ Î≥¥Ïïà/ÎùºÏù¥ÏÑ†Ïä§ Î¶¨Ìè¨Ìä∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Secret scan (gitleaks)
        uses: gitleaks/gitleaks-action@v2
        with:
          args: detect --no-git -v

      - name: License check (pip-licenses)
        shell: bash
        run: |
          set -Eeuo pipefail
          pip install pip-licenses
          mkdir -p security
          pip-licenses --format=json --with-authors --with-urls > security/pip-licenses.json
          echo "‚úÖ pip-licenses generated"

      # ‚îÄ‚îÄ Î¶¥Î¶¨Ï¶à (ÏòµÏÖò) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Ensure release-drafter config
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p .github
          cat > .github/release-drafter.yml <<'YML'
          name-template: 'v$NEXT_PATCH_VERSION'
          tag-template: 'v$NEXT_PATCH_VERSION'
          categories:
            - title: üöÄ Features
              labels: [feature, feat]
            - title: üêõ Fixes
              labels: [fix, bug]
          change-template: '- $TITLE (#$NUMBER) @$AUTHOR'
          YML
          echo "‚úÖ release-drafter.yml ready"

      - name: Draft release notes
        uses: release-drafter/release-drafter@v6
        with:
          config-name: release-drafter.yml
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate changelog (for release)
        if: ${{ steps.parse.outputs.rel_enable == 'true' }}
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p artifacts
          git fetch --tags --force || true
          PREV_TAG=$(git tag --sort=-creatordate | sed -n '2p')
          git log --pretty=format:"* %h %s (%an)" ${PREV_TAG}..HEAD > artifacts/CHANGELOG.txt || true
          [[ -s artifacts/CHANGELOG.txt ]] || echo "* Initial release" > artifacts/CHANGELOG.txt

      - name: Create GitHub Release
        if: ${{ steps.parse.outputs.rel_enable == 'true' }}
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.parse.outputs.rel_tag }}
          draft: ${{ steps.parse.outputs.rel_draft }}
          prerelease: ${{ steps.parse.outputs.rel_prerelease }}
          files: |
            artifacts/*.iso
            artifacts/*.sha256
            artifacts/*.sig
            artifacts/CHANGELOG.txt
            artifacts/*.tar.gz
            security/**
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # ‚îÄ‚îÄ ÏÑúÎ≤Ñ Î∞∞Ìè¨ (ÏòµÏÖò) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Deploy via SSH (optional)
        if: ${{ steps.parse.outputs.dep_enable == 'true' }}
        shell: bash
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SERVER_SSH_KEY }}
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          ROOT="workspace/${P}"
          HOST="${{ steps.parse.outputs.dep_host }}"
          USER="${{ steps.parse.outputs.dep_user }}"
          PORT="${{ steps.parse.outputs.dep_port }}"
          DEST="${{ steps.parse.outputs.dep_path }}"
          SVC="${{ steps.parse.outputs.dep_svc }}"
          CMD="${{ steps.parse.outputs.dep_cmd }}"
          USE_SUDO="${{ steps.parse.outputs.dep_sudo }}"
          [[ -z "$SSH_PRIVATE_KEY" ]] && { echo "‚ö†Ô∏è SERVER_SSH_KEY missing"; exit 0; }
          mkdir -p ~/.ssh
          echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh -o StrictHostKeyChecking=no -p "$PORT" "$USER@$HOST" "mkdir -p $DEST"
          rsync -az -e "ssh -p $PORT -o StrictHostKeyChecking=no" "$ROOT/" "$USER@$HOST:$DEST/"
          SUDO_FLAG=""; [[ "$USE_SUDO" == "true" ]] && SUDO_FLAG="SUDO=sudo"
          ssh -o StrictHostKeyChecking=no -p "$PORT" "$USER@$HOST" \
            "cd $DEST && $SUDO_FLAG APP_NAME=${P} DEPLOY_PATH=$DEST START_CMD='$CMD' bash ./server/install_deploy.sh"
          echo "‚úÖ deployed to $USER@$HOST:$DEST"

      - name: Post-deploy health check & rollback
        if: ${{ steps.parse.outputs.dep_enable == 'true' }}
        shell: bash
        run: |
          set -Eeuo pipefail
          HOST="${{ steps.parse.outputs.dep_host }}"
          USER="${{ steps.parse.outputs.dep_user }}"
          PORT="${{ steps.parse.outputs.dep_port }}"
          SVC="${{ steps.parse.outputs.dep_svc }}"
          ssh -o StrictHostKeyChecking=no -p "$PORT" "$USER@$HOST" \
            "systemctl is-active $SVC || (echo '‚ùå unhealthy, try restart'; sudo systemctl restart $SVC; sleep 2; systemctl is-active $SVC || (echo '‚ùå still unhealthy'; exit 1))"
          echo "‚úÖ service healthy"

      # ‚îÄ‚îÄ Dependabot & Artifacts & Cleanup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Write dependabot.yml
        shell: bash
        run: |
          set -Eeuo pipefail
          mkdir -p .github
          cat > .github/dependabot.yml <<'YML'
          version: 2
          updates:
            - package-ecosystem: pip
              directory: "/"
              schedule: { interval: weekly }
            - package-ecosystem: github-actions
              directory: "/"
              schedule: { interval: weekly }
          YML
          echo "‚úÖ dependabot.yml ready"

      - name: Upload artifacts (retention 7d)
        uses: actions/upload-artifact@v4
        with:
          name: echo-image-iso-${{ github.run_id }}
          path: |
            artifacts/**
            workspace/**/dist/**
            .github/echo_logs/**
            security/**
            iso_stage/**
            workspace/**/test-results/**
          if-no-files-found: warn
          retention-days: 7

      - name: Cleanup docker/apt cache
        if: ${{ always() }}
        shell: bash
        run: |
          set -Eeuo pipefail
          docker system prune -af || true
          sudo rm -rf /var/lib/apt/lists/* || true
          echo "‚úÖ cleanup done"
