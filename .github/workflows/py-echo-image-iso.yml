name: "🐍 PyPkg + Echo Dirs + Perm/Echo Files + Docker Image + ISO + CopyPlan (All-in-One)"

on:
  workflow_dispatch:
    inputs:
      package_name:
        description: "파이썬 패키지 이름 (PEP 8 소문자, 하이픈/점 금지)"
        required: true
        default: "mypkg"
      package_version:
        description: "패키지 버전"
        required: true
        default: "0.1.0"
      dirs_count:
        description: "대량 생성 디렉토리 개수 (예: 2000)"
        required: true
        default: "500"
      iso_label:
        description: "ISO 볼륨 라벨(영문/숫자/언더스코어)"
        required: true
        default: "ECHO_ISO"
      inject_info_json:
        description: "ISO에 주입할 JSON(예: {\"env\":\"prod\",\"team\":\"devops\"})"
        required: false
        default: "{\"env\":\"dev\",\"team\":\"finops\"}"
      metadata_json:
        description: "패키지 메타(JSON): {\"author_name\":\"...\",\"author_email\":\"...\",\"license_name\":\"MIT\"}"
        required: false
        default: "{\"author_name\":\"Your Name\",\"author_email\":\"you@example.com\",\"license_name\":\"MIT\"}"
      image_ref:
        description: "Docker 이미지 참조(이름:태그), 예: mypkg-app:latest"
        required: true
        default: "mypkg-app:latest"
      build_docker:
        description: "Docker 이미지 빌드/저장 수행"
        required: true
        type: boolean
        default: true
      copy_plan_json:
        description: >-
          디렉토리 복사 계획(JSON). 필드: src, dest_rel, include_globs[], exclude_globs[], max_mb, include_in_iso, required
          예: {"plans":[{"src":"samples","dest_rel":"extra/samples","include_globs":["**/*.md","**/*.txt"],"exclude_globs":["**/tmp/**"],"max_mb":50,"include_in_iso":true,"required":false}]}
        required: false
        default: "{\"plans\":[{\"src\":\"samples\",\"dest_rel\":\"extra/samples\",\"include_globs\":[\"**/*\"],\"exclude_globs\":[\"**/.git/**\",\"**/.github/**\"],\"max_mb\":100,\"include_in_iso\":true,\"required\":false}]}"

permissions:
  contents: write
  actions: read

env:
  TZ: Asia/Seoul
  LOG_DIR: .github/echo_logs
  ECHO_OK: "✅"
  ECHO_WARN: "⚠️"
  ECHO_FAIL: "❌"
  DOCKER_BUILDKIT: "1"

jobs:
  all-in-one:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # 모든 bash 스텝에서 에코 헬퍼 자동 로드 (현재 스텝 즉시 + 다음 스텝 자동)
      - name: Global echo helpers (persist across steps)
        shell: bash
        run: |
          set -Eeuo pipefail
          cat > "$GITHUB_WORKSPACE/.bashenv" <<'SH'
          ECHO_OK="${ECHO_OK:-✅}"
          ECHO_WARN="${ECHO_WARN:-⚠️}"
          ECHO_FAIL="${ECHO_FAIL:-❌}"
          LOG_DIR="${LOG_DIR:-.github/echo_logs}"
          mkdir -p "$LOG_DIR"
          SAFE_LOG="${SAFE_LOG:-${LOG_DIR}/run-$(date +%Y%m%d%H%M%S).log}"
          echoe(){ printf '%s %s\n' "${ECHO_OK}" "$*"; }
          warn(){  printf '%s %s\n' "${ECHO_WARN}" "$*"; }
          fail(){  printf '%s %s\n' "${ECHO_FAIL}" "$*"; }
          logf(){  printf '%s\n' "$*" | tee -a "$SAFE_LOG"; }
          SH
          export BASH_ENV="$GITHUB_WORKSPACE/.bashenv"
          echo "BASH_ENV=$BASH_ENV" >> "$GITHUB_ENV"
          bash -lc 'echoe "helpers loaded"; logf "helpers ready"'

      - name: Install toolchain (Python, ISO, copy utilities)
        shell: bash
        run: |
          set -Eeuo pipefail
          logf "Installing build/copy tools"
          sudo apt-get update -y
          sudo apt-get install -y python3 python3-venv python3-pip python3-setuptools python3-wheel \
              git jq rsync xorriso genisoimage dosfstools
          python3 --version | tee -a "$LOG_DIR/python.txt"
          pip3 --version | tee -a "$LOG_DIR/pip.txt"
          rsync --version | head -n1 | tee -a "$LOG_DIR/rsync.txt"
          logf "Installed: xorriso/genisoimage/jq/rsync"

      - name: Parse inputs (metadata_json, image_ref, copy_plan_json)
        id: parse
        shell: bash
        run: |
          set -Eeuo pipefail
          # metadata_json
          MJ='${{ inputs.metadata_json }}'
          A_NAME=$(printf '%s' "$MJ" | jq -r '.author_name // "Your Name"')
          A_EMAIL=$(printf '%s' "$MJ" | jq -r '.author_email // "you@example.com"')
          L_NAME=$(printf '%s' "$MJ" | jq -r '.license_name // "MIT"')

          # image_ref
          IMG='${{ inputs.image_ref }}'
          if [[ "$IMG" == *:* ]]; then
            IMG_NAME="${IMG%%:*}"
            IMG_TAG="${IMG##*:}"
          else
            IMG_NAME="$IMG"
            IMG_TAG="latest"
          fi

          # copy_plan_json
          CP='${{ inputs.copy_plan_json }}'
          printf '%s' "$CP" | jq . >/dev/null

          {
            echo "author_name=$A_NAME"
            echo "author_email=$A_EMAIL"
            echo "license_name=$L_NAME"
            echo "image_name=$IMG_NAME"
            echo "image_tag=$IMG_TAG"
          } | tee -a "$LOG_DIR/parsed_inputs.env"

          echo "author_name=$A_NAME"   >> "$GITHUB_OUTPUT"
          echo "author_email=$A_EMAIL" >> "$GITHUB_OUTPUT"
          echo "license_name=$L_NAME"  >> "$GITHUB_OUTPUT"
          echo "image_name=$IMG_NAME"  >> "$GITHUB_OUTPUT"
          echo "image_tag=$IMG_TAG"    >> "$GITHUB_OUTPUT"
          printf '%s' "$CP" > copy_plan.json
          logf "copy_plan.json saved"

      - name: Create Python package skeleton (PEP 621 / pyproject.toml)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          V="${{ inputs.package_version }}"
          A="${{ steps.parse.outputs.author_name }}"
          E="${{ steps.parse.outputs.author_email }}"
          L="${{ steps.parse.outputs.license_name }}"
          ROOT="workspace/${P}"
          PKG_DIR="$ROOT/src/${P}"
          TEST_DIR="$ROOT/tests"
          DOC_DIR="$ROOT/docs"
          mkdir -p "$PKG_DIR" "$TEST_DIR" "$DOC_DIR"

          # core files
          cat > "$ROOT/pyproject.toml" <<'PYT'
          [build-system]
          requires = ["setuptools>=68", "wheel"]
          build-backend = "setuptools.build_meta"

          [project]
          name = "__PKG_NAME__"
          version = "__PKG_VER__"
          description = "Auto-generated package with EchoOps"
          authors = [{ name="__AUTHOR__", email="__EMAIL__"}]
          license = { text="__LICENSE__" }
          readme = "README.md"
          requires-python = ">=3.9"
          classifiers = [
            "Programming Language :: Python :: 3",
            "License :: OSI Approved :: MIT License"
          ]

          [project.urls]
          Homepage = "https://example.com"

          [tool.setuptools.packages.find]
          where = ["src"]
          PYT
          sed -i "s/__PKG_NAME__/${P}/g" "$ROOT/pyproject.toml"
          sed -i "s/__PKG_VER__/${V}/g" "$ROOT/pyproject.toml"
          sed -i "s/__AUTHOR__/${A}/g" "$ROOT/pyproject.toml"
          sed -i "s/__EMAIL__/${E}/g" "$ROOT/pyproject.toml"
          sed -i "s/__LICENSE__/${L}/g" "$ROOT/pyproject.toml"

          cat > "$ROOT/README.md" <<'MD'
          # Auto Generated Python Package
          - EchoOps generated.
          - Includes Dockerfile, ISO injection artifacts, and copy-plan manifest.
          MD

          cat > "$PKG_DIR/__init__.py" <<'PY'
          __all__ = ["hello"]
          __version__ = "__VER__"
          def hello(name: str = "World") -> str:
              return f"Hello, {name}!"
          PY
          sed -i "s/__VER__/${V}/g" "$PKG_DIR/__init__.py"

          cat > "$TEST_DIR/test_hello.py" <<'PY'
          from __future__ import annotations
          from __pkg__.__init__ import hello
          def test_hello():
              assert hello("Echo") == "Hello, Echo!"
          PY
          sed -i "s/__pkg__/${P}/g" "$TEST_DIR/test_hello.py"

          # minimal Dockerfile
          cat > "$ROOT/Dockerfile" <<'DOCKER'
          FROM python:3.11-slim
          WORKDIR /app
          COPY . /app
          RUN pip install --no-cache-dir .
          CMD ["python","-c","import __PKG__; print(__PKG__.hello('Docker'))"]
          DOCKER
          sed -i "s/__PKG__/${P}/g" "$ROOT/Dockerfile"

          logf "Python skeleton created at $ROOT"

      - name: Build wheel / sdist
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          ROOT="workspace/${P}"
          python3 -m pip install --upgrade pip build
          python3 -m build "$ROOT"
          ls -al "$ROOT/dist" | tee -a "$LOG_DIR/dist.txt"

      - name: Massive directory generation (+ echo-style permission files)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          COUNT="${{ inputs.dirs_count }}"
          BASE="workspace/${P}/echo_mass"
          mkdir -p "$BASE"

          # echo-style script that grants perms and writes logs per dir
          cat > "$BASE/perm_apply.sh" <<'SH'
          #!/usr/bin/env bash
          set -Eeuo pipefail
          LOG_DIR="${LOG_DIR:-.github/echo_logs}"
          mkdir -p "$LOG_DIR"
          OUT="$LOG_DIR/perm-$(date +%Y%m%d%H%M%S).log"
          echo "perm started: $(date)" | tee -a "$OUT"
          for d in "$@"; do
            mkdir -p "$d"
            chmod 755 "$d"
            printf 'ECHO %s %s\n' "$(date +%Y-%m-%dT%H:%M:%S)" "$d" | tee -a "$OUT"
            echo "ok" > "$d/.echo.ok"
          done
          echo "done: $(date)" | tee -a "$OUT"
          SH
          chmod +x "$BASE/perm_apply.sh"

          # generate N dirs and apply
          mapfile -t DLIST < <(seq -w 1 "$COUNT" | xargs -I{} echo "$BASE/dir_{}")
          "${BASE}/perm_apply.sh" "${DLIST[@]}"
          logf "Generated $COUNT directories with permission echoes."

      # === [업데이트 반영] 디렉토리 복사 (경로 해석 + required + 용량 제한 + 매니페스트/체크섬 + ISO 포함 마커) ===
      - name: Copy directories by copy_plan_json (echo + manifest + checksums)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          ROOT="workspace/${P}"
          PLAN_FILE="copy_plan.json"
          DEST_BASE="$ROOT"  # dest_rel은 ROOT 기준

          [[ -f "$PLAN_FILE" ]] || { warn "copy_plan.json not found, skipping"; exit 0; }

          mkdir -p "$ROOT/extra_manifests"
          MANIFEST_CSV="$ROOT/extra_manifests/manifest-$(date +%Y%m%d%H%M%S).csv"
          echo "src,resolved_src,dest_rel,relpath,bytes,sha256" > "$MANIFEST_CSV"

          # 사람이 읽기 쉬운 사이즈 출력 (numfmt 없으면 bytes)
          nf(){ if command -v numfmt >/dev/null 2>&1; then numfmt --to=iec "$1"; else echo "$1 bytes"; fi; }

          COUNT_PLANS=$(jq -r '.plans | length' "$PLAN_FILE")
          logf "Copy plans: $COUNT_PLANS"

          for i in $(seq 0 $((COUNT_PLANS-1))); do
            SRC=$(jq -r ".plans[$i].src" "$PLAN_FILE")
            DEST_REL=$(jq -r ".plans[$i].dest_rel // \"extra\"" "$PLAN_FILE")
            MAX_MB=$(jq -r ".plans[$i].max_mb // 100" "$PLAN_FILE")
            INCLUDE_ISO=$(jq -r ".plans[$i].include_in_iso // true" "$PLAN_FILE")
            REQUIRED=$(jq -r ".plans[$i].required // false" "$PLAN_FILE")
            # arrays
            mapfile -t INCLUDES < <(jq -r ".plans[$i].include_globs[]?" "$PLAN_FILE")
            mapfile -t EXCLUDES < <(jq -r ".plans[$i].exclude_globs[]?" "$PLAN_FILE")

            # 경로 해석: repo-root → package-root → literal/absolute
            RESOLVED_SRC=""
            if [[ "$SRC" == /* ]]; then
              [[ -d "$SRC" ]] && RESOLVED_SRC="$SRC"
            else
              [[ -d "$GITHUB_WORKSPACE/$SRC" ]] && RESOLVED_SRC="$GITHUB_WORKSPACE/$SRC"
              [[ -z "$RESOLVED_SRC" && -d "$DEST_BASE/$SRC" ]] && RESOLVED_SRC="$DEST_BASE/$SRC"
              [[ -z "$RESOLVED_SRC" && -d "$SRC" ]] && RESOLVED_SRC="$SRC"
            fi

            if [[ -z "$RESOLVED_SRC" ]]; then
              if [[ "$REQUIRED" == "true" ]]; then
                fail "Plan[$i] required=true but src not found: $SRC (tried: $GITHUB_WORKSPACE/$SRC , $DEST_BASE/$SRC , $SRC)"
                exit 1
              else
                warn "Plan[$i] SRC not found: $SRC — skipping (set required=true to fail)"
                continue
              fi
            fi

            DEST_DIR="$DEST_BASE/$DEST_REL"
            mkdir -p "$DEST_DIR"

            logf "Plan[$i] SRC=$SRC → RESOLVED=$RESOLVED_SRC DEST_REL=$DEST_REL MAX_MB=${MAX_MB}MB INCLUDE_ISO=$INCLUDE_ISO REQUIRED=$REQUIRED"

            # rsync 필터 구성
            RSYNC_ARGS=(-a --delete --prune-empty-dirs)
            for p in "${INCLUDES[@]}";  do RSYNC_ARGS+=(--include "$p"); done
            for p in "${EXCLUDES[@]}";  do RSYNC_ARGS+=(--exclude "$p"); done
            RSYNC_ARGS+=(--exclude '.git/' --exclude '.github/')
            RSYNC_ARGS+=(--include '*/' --exclude '*') # include 매치된 파일만 복사

            # 임시 스테이징 후 용량 제한 검사
            TMP_STAGE="$(mktemp -d)"
            rsync "${RSYNC_ARGS[@]}" "$RESOLVED_SRC/" "$TMP_STAGE/"

            TOTAL_BYTES=$(du -sb "$TMP_STAGE" | awk '{print $1}')
            LIMIT_BYTES=$((MAX_MB * 1024 * 1024))

            if (( TOTAL_BYTES > LIMIT_BYTES )); then
              warn "Plan[$i] size exceed: $(nf "$TOTAL_BYTES") > $(nf "$LIMIT_BYTES"). Truncating by newest-first copy."
              mkdir -p "$DEST_DIR"
              REMAIN=$LIMIT_BYTES
              # 최신순 목록 (mtime 기준)
              mapfile -t FILES < <(find "$TMP_STAGE" -type f -printf '%T@ %p\n' | sort -nr | awk '{sub($1 FS,""); print}')
              for f in "${FILES[@]}"; do
                sz=$(stat -c%s "$f")
                (( sz <= REMAIN )) || continue
                rel="${f#"$TMP_STAGE/"}"
                mkdir -p "$DEST_DIR/$(dirname "$rel")"
                cp -a "$f" "$DEST_DIR/$rel"
                REMAIN=$((REMAIN - sz))
              done
            else
              # 전체 복사
              rsync -a --delete "$TMP_STAGE/" "$DEST_DIR/"
            fi

            # 매니페스트+체크섬
            if [[ -d "$DEST_DIR" ]]; then
              while IFS= read -r -d '' f; do
                rel="${f#"$DEST_BASE/"}"
                bytes=$(stat -c%s "$f")
                sha=$(sha256sum "$f" | awk '{print $1}')
                printf '%s,%s,%s,%s,%s\n' "$SRC" "$RESOLVED_SRC" "$DEST_REL" "${rel#"$DEST_REL/"}" "$bytes" "$sha" >> "$MANIFEST_CSV"
              done < <(find "$DEST_DIR" -type f -print0)
            fi

            rm -rf "$TMP_STAGE"

            # ISO 포함 표시 파일
            if [[ "$INCLUDE_ISO" == "true" ]]; then
              echo "include_in_iso=true" > "$DEST_DIR/.iso.include"
            else
              echo "include_in_iso=false" > "$DEST_DIR/.iso.include"
            fi

            logf "Plan[$i] done → $DEST_DIR"
          done

          logf "Manifest generated: $MANIFEST_CSV"

      - name: Optional Docker build + save
        if: ${{ inputs.build_docker == true }}
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          ROOT="workspace/${P}"
          IMG="${{ steps.parse.outputs.image_name }}:${{ steps.parse.outputs.image_tag }}"
          logf "Building Docker image: $IMG"
          docker build -t "$IMG" "$ROOT"
          mkdir -p artifacts
          docker save "$IMG" | gzip -c > "artifacts/${{ steps.parse.outputs.image_name }}-${{ steps.parse.outputs.image_tag }}.tar.gz"
          logf "Saved image tar.gz under artifacts/"

      - name: Prepare ISO staging & info injection (includes copied data)
        shell: bash
        run: |
          set -Eeuo pipefail
          P="${{ inputs.package_name }}"
          ROOT="workspace/${P}"
          STAGE="iso_stage/${P}"
          mkdir -p "$STAGE/config" "$STAGE/pkg" "$STAGE/docs" "$STAGE/extra"

          # Build metadata
          echo "${{ github.repository }},${{ github.run_id }},${{ github.ref_name }}" > "$STAGE/build_info.csv"

          # Inject user JSON
          printf '%s' '${{ inputs.inject_info_json }}' | jq . > "$STAGE/config/inject.json"

          # Include built distributions
          cp -a "$ROOT/dist" "$STAGE/pkg/"

          # Include echo logs & scripts
          cp -a .github/echo_logs "$STAGE/docs/" || true
          cp -a "$ROOT/echo_mass/perm_apply.sh" "$STAGE/docs/" || true

          # Include manifests
          if [[ -d "$ROOT/extra_manifests" ]]; then
            cp -a "$ROOT/extra_manifests" "$STAGE/docs/" || true
          fi

          # CopyPlan 결과 중 include_in_iso=true 만 ISO에 편입 (STAGE/extra 아래 반영)
          if [[ -d "$ROOT" ]]; then
            while IFS= read -r -d '' marker; do
              d="$(dirname "$marker")"
              rel="${d#"$ROOT/"}"
              mkdir -p "$STAGE/extra/$rel"
              rsync -a "$d/" "$STAGE/extra/$rel/"
            done < <(find "$ROOT" -type f -name ".iso.include" -print0 | xargs -0 grep -l "include_in_iso=true" || true)
          fi

          # README
          cat > "$STAGE/README.txt" <<'TXT'
          Echo ISO — includes:
          - pkg/dist: built wheels/sdists
          - config/inject.json: injected metadata
          - docs/echo_logs: run logs
          - docs/perm_apply.sh: permission script
          - docs/extra_manifests: copy-plan manifest & checksums
          - extra/*: directories copied per copy_plan (only include_in_iso=true)
          TXT

          logf "ISO staging prepared at $STAGE"

      - name: Build ISO (xorriso / genisoimage fallback)
        shell: bash
        run: |
          set -Eeuo pipefail
          ISO_NAME="${{ inputs.package_name }}-${{ inputs.package_version }}.iso"
          LABEL="${{ inputs.iso_label }}"
          STAGE="iso_stage/${{ inputs.package_name }}"
          mkdir -p artifacts
          if command -v xorriso >/dev/null 2>&1; then
            logf "Using xorriso"
            xorriso -as mkisofs -R -J -V "$LABEL" -o "artifacts/${ISO_NAME}" "$STAGE"
          else
            logf "Using genisoimage"
            genisoimage -R -J -V "$LABEL" -o "artifacts/${ISO_NAME}" "$STAGE"
          fi
          (cd artifacts && sha256sum "${ISO_NAME}" > "${ISO_NAME}.sha256" )
          logf "ISO built: artifacts/${ISO_NAME}"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: echo-image-iso-${{ github.run_id }}
          path: |
            artifacts/**
            workspace/**/dist/**
            .github/echo_logs/**
          if-no-files-found: warn
